MC-10:
  card_name: U-Net FCN
  dataset: Cityscapes
  git_commit: c685fe6767c4cadf6b051983ca6208f1b9d1ccb8
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 512, 1024]
  key_metric: mIoU
  license: Apache 2.0
  model_repository: https://github.com/open-mmlab/mmsegmentation/tree/main/configs/unet
  model_subversion: v1.2.2
  native_ml_model_path: ax_models/model_cards/mmlab/mmseg/unet_fcn-cityscapes.yaml
  native_ml_model_weight: s3://axelera-model-card/weights/mmlab/semantic_segmentation/fcn_unet_s5-d16_4x4_512x1024_160k_cityscapes_20211210_145204-6860854e.pth
  native_ml_yaml_description: U-Net FCN from MMSegmentation
  native_ml_yaml_name: unet_fcn-cityscapes
  num_classes: 19
  onnx_model_path: ax_models/model_cards/mmlab/mmseg/unet_fcn-cityscapes-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/mmlab/semantic_segmentation/fcn_unet_s5-d16_4x4_512x1024_160k_cityscapes_20211210_145204-6860854e.onnx
  onnx_yaml_description: U-Net FCN from MMSegmentation, ONNX is converted from mmdeploy
    (0.1.2)
  onnx_yaml_name: unet_fcn-cityscapes-onnx
  production_ML_framework: PyTorch
  task_category: SemanticSegmentation
MC-106:
  card_name: VGG16
  dataset: ImageNet-1K
  git_commit: bddbd7e6d65ecacc2e40cf6c9e2059669b8dbd44
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 224, 224]
  key_metric: Top1
  license: BSD-3-Clause
  model_repository: https://github.com/pytorch/vision
  model_subversion: v0.13.1
  native_ml_model_path: ax_models/model_cards/torchvision/classification/vgg16-imagenet.yaml
  native_ml_model_weight: ''
  native_ml_yaml_description: VGG16 (ImageNet) - v1.5 from torchvision
  native_ml_yaml_name: vgg16-imagenet
  num_classes: 1000
  onnx_model_path: ax_models/model_cards/torchvision/classification/vgg16-imagenet-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/classification/vgg16_pretrained.onnx
  onnx_yaml_description: VGG16 (ImageNet) trained from torchvision and converted as
    ONNX
  onnx_yaml_name: vgg16-imagenet-onnx
  production_ML_framework: PyTorch
  task_category: Classification
MC-110:
  card_name: DenseNet-121
  dataset: ImageNet-1K
  git_commit: bddbd7e6d65ecacc2e40cf6c9e2059669b8dbd44
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 224, 224]
  key_metric: Top1
  license: BSD-3-Clause
  model_repository: https://github.com/pytorch/vision
  model_subversion: v0.13.1
  native_ml_model_path: ax_models/model_cards/torchvision/classification/densenet121-imagenet.yaml
  native_ml_model_weight: ''
  native_ml_yaml_description: DenseNet-121 (ImageNet) - v1.5 from torchvision
  native_ml_yaml_name: densenet121-imagenet
  num_classes: 1000
  onnx_model_path: ax_models/model_cards/torchvision/classification/densenet121-imagenet-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/classification/densenet121_pretrained.onnx
  onnx_yaml_description: DenseNet-121 (ImageNet) trained from torchvision and converted
    as ONNX
  onnx_yaml_name: densenet121-imagenet-onnx
  production_ML_framework: PyTorch
  task_category: Classification
MC-111:
  card_name: DenseNet-161
  dataset: ImageNet-1K
  git_commit: bddbd7e6d65ecacc2e40cf6c9e2059669b8dbd44
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 224, 224]
  key_metric: Top1
  license: BSD-3-Clause
  model_repository: https://github.com/pytorch/vision
  model_subversion: v0.13.1
  native_ml_model_path: ax_models/model_cards/torchvision/classification/densenet161-imagenet.yaml
  native_ml_model_weight: ''
  native_ml_yaml_description: DenseNet-161 (ImageNet) - v1.5 from torchvision
  native_ml_yaml_name: densenet161-imagenet
  num_classes: 1000
  onnx_model_path: ax_models/model_cards/torchvision/classification/densenet161-imagenet-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/classification/densenet161_pretrained.onnx
  onnx_yaml_description: DenseNet-161 (ImageNet) trained from torchvision and converted
    as ONNX
  onnx_yaml_name: densenet161-imagenet-onnx
  production_ML_framework: PyTorch
  task_category: Classification
MC-121:
  card_name: LPRNet
  dataset: LPRNetDataset
  git_commit: 7c976664b3f3879efabeaff59c7a117e49d5f29e
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 24, 94]
  key_metric: WLA_average
  license: Apache-2.0
  model_repository: https://github.com/sirius-ai/LPRNet_Pytorch
  model_subversion: null
  native_ml_model_path: ax_models/model_cards/torch/lprnet.yaml
  native_ml_model_weight: s3://axelera-model-card/app_weights/license_plate_recog/Final_LPRNet_model.pth
  native_ml_yaml_description: PyTorch implementation of LPRNet
  native_ml_yaml_name: lprnet
  num_classes: 68
  onnx_model_path: ax_models/model_cards/torch/lprnet-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/app_weights/license_plate_recog/lprnet.onnx
  onnx_yaml_description: Converted from PyTorch implementation of LPRNet
  onnx_yaml_name: lprnet-onnx
  production_ML_framework: PyTorch
  task_category: LicensePlateRecognition
MC-123:
  card_name: Inception V3
  dataset: ImageNet-1K
  git_commit: bddbd7e6d65ecacc2e40cf6c9e2059669b8dbd44
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 224, 224]
  key_metric: Top1
  license: BSD-3-Clause
  model_repository: https://github.com/pytorch/vision
  model_subversion: v0.13.1
  native_ml_model_path: ax_models/model_cards/torchvision/classification/inception_v3-imagenet.yaml
  native_ml_model_weight: ''
  native_ml_yaml_description: Inception V3 (ImageNet) - v1.5 from torchvision
  native_ml_yaml_name: inception_v3-imagenet
  num_classes: 1000
  onnx_model_path: ax_models/model_cards/torchvision/classification/inception_v3-imagenet-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/classification/inception_v3_pretrained.onnx
  onnx_yaml_description: Inception V3 (ImageNet) trained from torchvision and converted
    as ONNX
  onnx_yaml_name: inception_v3-imagenet-onnx
  production_ML_framework: PyTorch
  task_category: Classification
MC-13:
  card_name: YOLOv8m-pose
  dataset: CocoDataset-keypoint-COCO2017
  git_commit: 0b7edb54544a245e3cb38bede156ffeda8e5d3d3
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 640, 640]
  key_metric: mAP
  license: AGPL-3.0
  model_repository: https://github.com/ultralytics/ultralytics
  model_subversion: v8.1.0
  native_ml_model_path: ax_models/model_cards/yolo/keypoint_detection/yolov8mpose-coco.yaml
  native_ml_model_weight: https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8m-pose.pt
  native_ml_yaml_description: yolov8m pose estimation ultralytics v8.1.0, 640x640
    (COCO), native PyTorch model
  native_ml_yaml_name: yolov8mpose-coco
  num_classes: 1
  onnx_model_path: ax_models/model_cards/yolo/keypoint_detection/yolov8mpose-coco-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/yolo/keypoint_detection/yolov8m-pose-v8.1.onnx
  onnx_yaml_description: yolov8m pose estimation ultralytics v8.1.0, 640x640 (COCO)
  onnx_yaml_name: yolov8mpose-coco-onnx
  production_ML_framework: PyTorch
  task_category: KeypointDetection
MC-142:
  card_name: ResNet-18
  dataset: ImageNet-1K
  git_commit: bddbd7e6d65ecacc2e40cf6c9e2059669b8dbd44
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 224, 224]
  key_metric: Top1
  license: BSD-3-Clause
  model_repository: https://github.com/pytorch/vision
  model_subversion: v0.13.1
  native_ml_model_path: ax_models/model_cards/torchvision/classification/resnet18-imagenet.yaml
  native_ml_model_weight: ''
  native_ml_yaml_description: ResNet 18 (ImageNet) - v1.5 from torchvision
  native_ml_yaml_name: resnet18-imagenet
  num_classes: 1000
  onnx_model_path: ax_models/model_cards/torchvision/classification/resnet18-imagenet-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/classification/resnet18_pretrained.onnx
  onnx_yaml_description: resnet18 (ImageNet) trained from torchvision and converted
    as ONNX
  onnx_yaml_name: resnet18-imagenet-onnx
  production_ML_framework: PyTorch
  task_category: Classification
MC-143:
  card_name: MobileNetV3-large
  dataset: ImageNet-1K
  git_commit: bddbd7e6d65ecacc2e40cf6c9e2059669b8dbd44
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 224, 224]
  key_metric: Top1
  license: BSD-3-Clause
  model_repository: https://github.com/pytorch/vision
  model_subversion: v0.13.1
  native_ml_model_path: ax_models/model_cards/torchvision/classification/mobilenetv3_large-imagenet.yaml
  native_ml_model_weight: ''
  native_ml_yaml_description: mobilenetv3_large (ImageNet) from torchvision
  native_ml_yaml_name: mobilenetv3_large-imagenet
  num_classes: 1000
  onnx_model_path: ax_models/model_cards/torchvision/classification/mobilenetv3_large-imagenet-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/classification/mobilenet_v3_large_pretrained.onnx
  onnx_yaml_description: mobilenetv3_large (ImageNet) trained from torchvision and
    converted as ONNX
  onnx_yaml_name: mobilenetv3_large-imagenet-onnx
  production_ML_framework: PyTorch
  task_category: Classification
MC-144:
  card_name: YOLOv7 640x480
  dataset: CocoDataset-COCO2017
  git_commit: a207844b1ce82d204ab36d87d496728d3d2348e7
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 480, 640]
  key_metric: mAP
  license: GPL-3.0
  model_repository: https://github.com/WongKinYiu/yolov7
  model_subversion: v0.1
  native_ml_model_path: ax_models/model_cards/yolo/object_detection/yolov7-640x480-coco.yaml
  native_ml_model_weight: s3://axelera-model-card/weights/yolo/object_detection/yolov7.pt
  native_ml_yaml_description: YOLOv7 640x480 (COCO)
  native_ml_yaml_name: yolov7-640x480-coco
  num_classes: 80
  onnx_model_path: ax_models/model_cards/yolo/object_detection/yolov7-640x480-coco-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/yolo/object_detection/yolov7-640x480.onnx
  onnx_yaml_description: YOLOv7-v0.1 ONNX with rectangular inference (COCO)
  onnx_yaml_name: yolov7-640x480-coco-onnx
  production_ML_framework: PyTorch
  task_category: ObjectDetection
MC-145:
  card_name: ResNet-50 v1.0
  dataset: ImageNet-1K
  git_commit: 601488fd4c1468ae7872e132e0f1c9843df54182
  input_color_format: BGR
  input_tensor_layout: NHWC
  input_tensor_shape: [1, 224, 224, 3]
  key_metric: Top1
  license: Apache 2.0
  model_repository: https://github.com/keras-team/keras/blob/v2.15.0/keras/applications/resnet.py
  model_subversion: v2.15.0
  num_classes: 1000
  onnx_model_path: ax_models/model_cards/tensorflow/classification/resnet50-imagenet-tf2-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/classification/tf2_resnet50.onnx
  onnx_yaml_description: Resnet50v1 (ImageNet) trained from tensorflow2 and converted
    as ONNX
  onnx_yaml_name: resnet50-imagenet-tf2-onnx
  production_ML_framework: Tensorflow2
  task_category: Classification
MC-148:
  card_name: YOLOv5s-v5
  dataset: CocoDataset-COCO2017
  git_commit: f5b8f7d54c9fa69210da0177fec7ac2d9e4a627c
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 640, 640]
  key_metric: mAP
  license: AGPL-3.0
  model_repository: https://github.com/ultralytics/yolov5
  model_subversion: v5.0
  native_ml_model_path: ax_models/model_cards/yolo/object_detection/yolov5s-v5-coco.yaml
  native_ml_model_weight: s3://axelera-model-card/weights/yolo/object_detection/yolov5s-v5.pt
  native_ml_yaml_description: YOLOv5s-v5 with Focus layer, SiLU, S2D on the host,
    640x640 (COCO)
  native_ml_yaml_name: yolov5s-v5-coco
  num_classes: 80
  onnx_model_path: ax_models/model_cards/yolo/object_detection/yolov5s-v5-coco-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/yolo/object_detection/yolov5s-v5-op11.onnx
  onnx_yaml_description: YOLOv5s-v5 ONNX with Focus layer, SiLU, S2D on the host,
    640x640 (COCO)
  onnx_yaml_name: yolov5s-v5-coco-onnx
  production_ML_framework: PyTorch
  task_category: ObjectDetection
MC-156:
  card_name: MnasNet0_75
  dataset: ImageNet-1K
  git_commit: bddbd7e6d65ecacc2e40cf6c9e2059669b8dbd44
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 224, 224]
  key_metric: Top1
  license: BSD-3-Clause
  model_repository: https://github.com/pytorch/vision
  model_subversion: v0.13.1
  native_ml_model_path: ax_models/model_cards/torchvision/classification/mnasnet0_75-imagenet.yaml
  native_ml_model_weight: ''
  native_ml_yaml_description: MnasNet0_75 (ImageNet) - v1.5 from torchvision
  native_ml_yaml_name: mnasnet0_75-imagenet
  num_classes: 1000
  onnx_model_path: ax_models/model_cards/torchvision/classification/mnasnet0_75-imagenet-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/classification/mnasnet0_75_pretrained.onnx
  onnx_yaml_description: MnasNet0_75 (ImageNet) trained from torchvision and converted
    as ONNX
  onnx_yaml_name: mnasnet0_75-imagenet-onnx
  production_ML_framework: PyTorch
  task_category: Classification
MC-161:
  card_name: MnasNet0_5
  dataset: ImageNet-1K
  git_commit: bddbd7e6d65ecacc2e40cf6c9e2059669b8dbd44
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 224, 224]
  key_metric: Top1
  license: BSD-3-Clause
  model_repository: https://github.com/pytorch/vision
  model_subversion: v0.13.1
  native_ml_model_path: ax_models/model_cards/torchvision/classification/mnasnet0_5-imagenet.yaml
  native_ml_model_weight: ''
  native_ml_yaml_description: MnasNet0_5 (ImageNet) - v1.5 from torchvision
  native_ml_yaml_name: mnasnet0_5-imagenet
  num_classes: 1000
  onnx_model_path: ax_models/model_cards/torchvision/classification/mnasnet0_5-imagenet-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/classification/mnasnet0_5_pretrained.onnx
  onnx_yaml_description: MnasNet0_5 (ImageNet) trained from torchvision and converted
    as ONNX
  onnx_yaml_name: mnasnet0_5-imagenet-onnx
  production_ML_framework: PyTorch
  task_category: Classification
MC-162:
  card_name: MnasNet1_0
  dataset: ImageNet-1K
  git_commit: bddbd7e6d65ecacc2e40cf6c9e2059669b8dbd44
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 224, 224]
  key_metric: Top1
  license: BSD-3-Clause
  model_repository: https://github.com/pytorch/vision
  model_subversion: v0.13.1
  native_ml_model_path: ax_models/model_cards/torchvision/classification/mnasnet1_0-imagenet.yaml
  native_ml_model_weight: ''
  native_ml_yaml_description: MNASNet1_0 (ImageNet) - v1.5 from torchvision
  native_ml_yaml_name: mnasnet1_0-imagenet
  num_classes: 1000
  onnx_model_path: ax_models/model_cards/torchvision/classification/mnasnet1_0-imagenet-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/classification/mnasnet1_0_pretrained.onnx
  onnx_yaml_description: MNASNet1_0 (ImageNet) trained from torchvision and converted
    as ONNX
  onnx_yaml_name: mnasnet1_0-imagenet-onnx
  production_ML_framework: PyTorch
  task_category: Classification
MC-163:
  card_name: MnasNet1_3
  dataset: ImageNet-1K
  git_commit: bddbd7e6d65ecacc2e40cf6c9e2059669b8dbd44
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 224, 224]
  key_metric: Top1
  license: BSD-3-Clause
  model_repository: https://github.com/pytorch/vision
  model_subversion: v0.13.1
  native_ml_model_path: ax_models/model_cards/torchvision/classification/mnasnet1_3-imagenet.yaml
  native_ml_model_weight: ''
  native_ml_yaml_description: MNASNet1_3 (ImageNet) - v1.5 from torchvision
  native_ml_yaml_name: mnasnet1_3-imagenet
  num_classes: 1000
  onnx_model_path: ax_models/model_cards/torchvision/classification/mnasnet1_3-imagenet-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/classification/mnasnet1_3_pretrained.onnx
  onnx_yaml_description: MnasNett1_3 (ImageNet) trained from torchvision and converted
    as ONNX
  onnx_yaml_name: mnasnet1_3-imagenet-onnx
  production_ML_framework: PyTorch
  task_category: Classification
MC-165:
  card_name: SqueezeNet 1.1
  dataset: ImageNet-1K
  git_commit: bddbd7e6d65ecacc2e40cf6c9e2059669b8dbd44
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 224, 224]
  key_metric: Top1
  license: BSD-3-Clause
  model_repository: https://github.com/pytorch/vision
  model_subversion: v0.13.1
  native_ml_model_path: ax_models/model_cards/torchvision/classification/squeezenet1.1-imagenet.yaml
  native_ml_model_weight: ''
  native_ml_yaml_description: SqueezeNet 1.1 (ImageNet)
  native_ml_yaml_name: squeezenet1.1-imagenet
  num_classes: 1000
  onnx_model_path: ax_models/model_cards/torchvision/classification/squeezenet1.1-imagenet-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/classification/squeezenet1_1_pretrained.onnx
  onnx_yaml_description: squeezenet1.1 (ImageNet) trained from torchvision and converted
    as ONNX
  onnx_yaml_name: squeezenet1.1-imagenet-onnx
  production_ML_framework: PyTorch
  task_category: Classification
MC-166:
  card_name: ResNet-101
  dataset: ImageNet-1K
  git_commit: bddbd7e6d65ecacc2e40cf6c9e2059669b8dbd44
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 224, 224]
  key_metric: Top1
  license: BSD-3-Clause
  model_repository: https://github.com/pytorch/vision
  model_subversion: v0.13.1
  native_ml_model_path: ax_models/model_cards/torchvision/classification/resnet101-imagenet.yaml
  native_ml_model_weight: ''
  native_ml_yaml_description: ResNet 101 (ImageNet) - v1.5 from torchvision
  native_ml_yaml_name: resnet101-imagenet
  num_classes: 1000
  onnx_model_path: ax_models/model_cards/torchvision/classification/resnet101-imagenet-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/classification/resnet101_pretrained.onnx
  onnx_yaml_description: resnet101 (ImageNet) trained from torchvision and converted
    as ONNX
  onnx_yaml_name: resnet101-imagenet-onnx
  production_ML_framework: PyTorch
  task_category: Classification
MC-167:
  card_name: ResNet-152
  dataset: ImageNet-1K
  git_commit: bddbd7e6d65ecacc2e40cf6c9e2059669b8dbd44
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 224, 224]
  key_metric: Top1
  license: BSD-3-Clause
  model_repository: https://github.com/pytorch/vision
  model_subversion: v0.13.1
  native_ml_model_path: ax_models/model_cards/torchvision/classification/resnet152-imagenet.yaml
  native_ml_model_weight: ''
  native_ml_yaml_description: ResNet 152 (ImageNet) - v1.5 from torchvision
  native_ml_yaml_name: resnet152-imagenet
  num_classes: 1000
  onnx_model_path: ax_models/model_cards/torchvision/classification/resnet152-imagenet-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/classification/resnet152_pretrained.onnx
  onnx_yaml_description: resnet152 (ImageNet) trained from torchvision and converted
    as ONNX
  onnx_yaml_name: resnet152-imagenet-onnx
  production_ML_framework: PyTorch
  task_category: Classification
MC-168:
  card_name: Wide ResNet-50
  dataset: ImageNet-1K
  git_commit: bddbd7e6d65ecacc2e40cf6c9e2059669b8dbd44
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 224, 224]
  key_metric: Top1
  license: BSD-3-Clause
  model_repository: https://github.com/pytorch/vision
  model_subversion: v0.13.1
  native_ml_model_path: ax_models/model_cards/torchvision/classification/wide_resnet50-imagenet.yaml
  native_ml_model_weight: ''
  native_ml_yaml_description: Wide ResNet-50 (ImageNet) - v1.5 from torchvision
  native_ml_yaml_name: wide_resnet50-imagenet
  num_classes: 1000
  onnx_model_path: ax_models/model_cards/torchvision/classification/wide_resnet50-imagenet-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/classification/wide_resnet50_2_pretrained.onnx
  onnx_yaml_description: Wide ResNet-50 (ImageNet) trained from torchvision and converted
    as ONNX
  onnx_yaml_name: wide_resnet50-imagenet-onnx
  production_ML_framework: PyTorch
  task_category: Classification
MC-169:
  card_name: YOLOv6m
  dataset: CocoDataset-COCO2017
  git_commit: 87dd3d3963b6b373ccdc626b9bae5a2afec5639e
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 640, 640]
  key_metric: mAP
  license: GPL-3.0
  model_repository: https://github.com/meituan/YOLOv6
  model_subversion: v0.4.1
  num_classes: 80
  onnx_model_path: ax_models/model_cards/yolo/object_detection/yolov6m-coco-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/yolo/object_detection/yolov6m.onnx
  onnx_yaml_description: YOLOv6m, input size 640x640 (COCO)
  onnx_yaml_name: yolov6m-coco-onnx
  production_ML_framework: PyTorch
  task_category: ObjectDetection
MC-170:
  card_name: YOLOX-s
  dataset: CocoDataset-COCO2017
  git_commit: ac58e0a5e68e57454b7b9ac822aced493b553c53
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 640, 640]
  key_metric: mAP
  license: Apache-2.0
  model_repository: https://github.com/Megvii-BaseDetection/YOLOX
  model_subversion: v0.3.0
  num_classes: 80
  onnx_model_path: ax_models/model_cards/yolo/object_detection/yolox-s-coco-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/yolo/object_detection/yolox_s.onnx
  onnx_yaml_description: YOLOX-s v0.3.0, ONNX with preprocessed Focus layer, input
    size 640x640 (COCO), anchor free model
  onnx_yaml_name: yolox-s-coco-onnx
  production_ML_framework: PyTorch
  task_category: ObjectDetection
MC-171:
  card_name: YOLOv3-tiny
  dataset: CocoDataset-COCO2017
  git_commit: ff22af7948af2d321c15627749bc761aq
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 640, 640]
  key_metric: mAP
  license: AGPL-3.0
  model_repository: https://github.com/ultralytics/yolov3
  model_subversion: v9.6.0
  num_classes: 80
  onnx_model_path: ax_models/model_cards/yolo/object_detection/yolov3tiny-coco-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/yolo/object_detection/yolov3tiny.onnx
  onnx_yaml_description: yolov3-tiny ultralytics v9.6.0, input size 640x640 (COCO)
  onnx_yaml_name: yolov3tiny-coco-onnx
  production_ML_framework: PyTorch
  task_category: ObjectDetection
MC-172:
  card_name: YOLOv8n
  dataset: CocoDataset-COCO2017
  git_commit: 0b7edb54544a245e3cb38bede156ffeda8e5d3d3
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 640, 640]
  key_metric: mAP
  license: AGPL-3.0
  model_repository: https://github.com/ultralytics/ultralytics
  model_subversion: v8.1.0
  native_ml_model_path: ax_models/model_cards/yolo/object_detection/yolov8n-coco.yaml
  native_ml_model_weight: https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt
  native_ml_yaml_description: yolov8n ultralytics v8.1.0, 640x640 (COCO), anchor free
    model, native PyTorch model
  native_ml_yaml_name: yolov8n-coco
  num_classes: 80
  onnx_model_path: ax_models/model_cards/yolo/object_detection/yolov8n-coco-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/yolo/object_detection/yolov8n_ultralytics_v8.1.0.onnx
  onnx_yaml_description: yolov8n ultralytics v8.1.0, 640x640 (COCO), anchor free model
  onnx_yaml_name: yolov8n-coco-onnx
  production_ML_framework: PyTorch
  task_category: ObjectDetection
MC-174:
  card_name: YOLOv9c
  dataset: CocoDataset-COCO2017
  git_commit: 6e43d1e1e5db72afbf686dee6745669bcb124b0a
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 640, 640]
  key_metric: mAP
  license: AGPL-3.0
  model_repository: https://github.com/ultralytics/ultralytics
  model_subversion: v8.3.0
  num_classes: 80
  onnx_model_path: ax_models/model_cards/yolo/object_detection/yolov9c-coco-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/yolo/object_detection/yolov9c-8.3-dynamic.onnx
  onnx_yaml_description: yolov9c, 640x640 (COCO), anchor free model
  onnx_yaml_name: yolov9c-coco-onnx
  production_ML_framework: PyTorch
  task_category: ObjectDetection
MC-176:
  card_name: YOLOv8n-pose
  dataset: CocoDataset-keypoint-COCO2017
  git_commit: 0b7edb54544a245e3cb38bede156ffeda8e5d3d3
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 640, 640]
  key_metric: mAP
  license: AGPL-3.0
  model_repository: https://github.com/ultralytics/ultralytics
  model_subversion: v8.1.0
  native_ml_model_path: ax_models/model_cards/yolo/keypoint_detection/yolov8npose-coco.yaml
  native_ml_model_weight: https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n-pose.pt
  native_ml_yaml_description: yolov8n pose estimation ultralytics v8.1.0, 640x640
    (COCO), native PyTorch model
  native_ml_yaml_name: yolov8npose-coco
  num_classes: 1
  onnx_model_path: ax_models/model_cards/yolo/keypoint_detection/yolov8npose-coco-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/yolo/keypoint_detection/yolov8n-pose-v8.1.onnx
  onnx_yaml_description: yolov8n pose estimation ultralytics v8.1.0, 640x640 (COCO)
  onnx_yaml_name: yolov8npose-coco-onnx
  production_ML_framework: PyTorch
  task_category: KeypointDetection
MC-177:
  card_name: YOLOv8n-seg
  dataset: CocoDataset-Segment-COCO2017
  git_commit: 0b7edb54544a245e3cb38bede156ffeda8e5d3d3
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 640, 640]
  key_metric: mAP
  license: AGPL-3.0
  model_repository: https://github.com/ultralytics/ultralytics
  model_subversion: v8.1.0
  native_ml_model_path: ax_models/model_cards/yolo/instance_segmentation/yolov8nseg-coco.yaml
  native_ml_model_weight: https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n-seg.pt
  native_ml_yaml_description: yolov8n seg estimation ultralytics v8.1.0, 640x640 (COCO),
    native PyTorch model
  native_ml_yaml_name: yolov8nseg-coco
  num_classes: 80
  onnx_model_path: ax_models/model_cards/yolo/instance_segmentation/yolov8nseg-coco-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/yolo/instance_segmentation/yolov8n-seg-v8.1.onnx
  onnx_yaml_description: yolov8n seg estimation ultralytics v8.1.0, 640x640 (COCO)
  onnx_yaml_name: yolov8nseg-coco-onnx
  production_ML_framework: PyTorch
  task_category: InstanceSegmentation
MC-178:
  card_name: YOLOv8m-seg
  dataset: CocoDataset-Segment-COCO2017
  git_commit: 0b7edb54544a245e3cb38bede156ffeda8e5d3d3
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 640, 640]
  key_metric: mAP
  license: AGPL-3.0
  model_repository: https://github.com/ultralytics/ultralytics
  model_subversion: v8.1.0
  native_ml_model_path: ax_models/model_cards/yolo/instance_segmentation/yolov8mseg-coco.yaml
  native_ml_model_weight: https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8m-seg.pt
  native_ml_yaml_description: yolov8m seg estimation ultralytics v8.1.0, 640x640 (COCO),
    native PyTorch model
  native_ml_yaml_name: yolov8mseg-coco
  num_classes: 80
  onnx_model_path: ax_models/model_cards/yolo/instance_segmentation/yolov8mseg-coco-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/yolo/instance_segmentation/yolov8m-seg-v8.1.onnx
  onnx_yaml_description: yolov8m seg estimation ultralytics v8.1.0, 640x640 (COCO)
  onnx_yaml_name: yolov8mseg-coco-onnx
  production_ML_framework: PyTorch
  task_category: InstanceSegmentation
MC-181:
  card_name: RetinaFace - Resnet50
  dataset: WiderFace
  git_commit: b984b4b775b2c4dced95c1eadd195a5c7d32a60b
  input_color_format: BGR
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 840, 840]
  key_metric: mAP
  license: MIT
  model_repository: https://github.com/biubug6/Pytorch_Retinaface/tree/master
  model_subversion: N/A
  num_classes: 1
  onnx_model_path: ax_models/model_cards/torch/retinaface-resnet50-widerface-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/others/object_detection/Retinaface_resnet50_840.onnx
  onnx_yaml_description: RetinaFace face detection and landmark localization model
    trained on WiderFace dataset with ResNet50 backbone
  onnx_yaml_name: retinaface-resnet50-widerface-onnx
  production_ML_framework: PyTorch
  task_category: ObjectDetection
MC-182:
  card_name: YOLOv8s-seg
  dataset: CocoDataset-Segment-COCO2017
  git_commit: 69cfc8aa228dbf1267975f82fcae9a24665f23b9
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 640, 640]
  key_metric: mAP
  license: AGPL-3.0
  model_repository: https://github.com/ultralytics/ultralytics
  model_subversion: v8.2.45
  native_ml_model_path: ax_models/model_cards/yolo/instance_segmentation/yolov8sseg-coco.yaml
  native_ml_model_weight: https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8s-seg.pt
  native_ml_yaml_description: yolov8s seg estimation ultralytics v8.2, 640x640 (COCO),
    native PyTorch model
  native_ml_yaml_name: yolov8sseg-coco
  num_classes: 80
  onnx_model_path: ax_models/model_cards/yolo/instance_segmentation/yolov8sseg-coco-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/yolo/instance_segmentation/yolov8s-seg-v8.2.onnx
  onnx_yaml_description: yolov8s seg estimation ultralytics v8.2, 640x640 (COCO)
  onnx_yaml_name: yolov8sseg-coco-onnx
  production_ML_framework: PyTorch
  task_category: InstanceSegmentation
MC-183:
  card_name: YOLOv8l-seg
  dataset: CocoDataset-Segment-COCO2017
  git_commit: 69cfc8aa228dbf1267975f82fcae9a24665f23b9
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 640, 640]
  key_metric: mAP
  license: AGPL-3.0
  model_repository: https://github.com/ultralytics/ultralytics
  model_subversion: v8.2.45
  native_ml_model_path: ax_models/model_cards/yolo/instance_segmentation/yolov8lseg-coco.yaml
  native_ml_model_weight: https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8l-seg.pt
  native_ml_yaml_description: yolov8l seg estimation ultralytics v8.2, 640x640 (COCO),
    native PyTorch model
  native_ml_yaml_name: yolov8lseg-coco
  num_classes: 80
  onnx_model_path: ax_models/model_cards/yolo/instance_segmentation/yolov8lseg-coco-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/yolo/instance_segmentation/yolov8l-seg-v8.2.onnx
  onnx_yaml_description: yolov8l seg estimation ultralytics v8.2, 640x640 (COCO)
  onnx_yaml_name: yolov8lseg-coco-onnx
  production_ML_framework: PyTorch
  task_category: InstanceSegmentation
MC-184:
  card_name: FaceNet - InceptionResnetV1
  dataset: LFWTorchvisionPair
  git_commit: 8ee5326dc904f88846ca014a3d047b08392bd12f
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 160, 160]
  key_metric: Top1
  license: MIT
  model_repository: https://github.com/timesler/facenet-pytorch
  model_subversion: v2.5.3
  native_ml_model_path: ax_models/model_cards/torch/facenet-lfw.yaml
  native_ml_model_weight: s3://axelera-model-card/weights/face_recognition/facenet_vgg_face_2.pt
  native_ml_yaml_description: FaceNet - InceptionResnetV1 with vggface2 weights for
    face recognition
  native_ml_yaml_name: facenet-lfw
  num_classes: 3131
  onnx_model_path: ax_models/model_cards/torch/facenet-lfw-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/face_recognition/facenet.onnx
  onnx_yaml_description: FaceNet - InceptionResnetV1 with vggface2 weights for face
    recognition, converted from PyTorch to ONNX
  onnx_yaml_name: facenet-lfw-onnx
  production_ML_framework: PyTorch
  task_category: FaceRecognition
MC-187:
  card_name: Phi3-mini (2048)
  dataset: ''
  git_commit: null
  icdf_model_path: ax_models/model_cards/llm/phi3-mini-2048-4core-static.yaml
  icdf_model_weight: https://llm.axelera.ai/icdf/4.x/phi3_2048_mc_model.tar.gz
  icdf_yaml_description: HuggingFace Transformers Phi-3-mini-4k-instruct model, limiting
    the sequence length to 2048 tokens, compiled for 4 cores execution
  icdf_yaml_name: phi3-mini-2048-4core-static
  input_color_format: null
  input_tensor_layout: null
  input_tensor_shape: null
  key_metric: LLM
  license: MIT
  model_repository: https://huggingface.co/microsoft/Phi-3-mini-4k-instruct
  model_subversion: 4core
  num_classes: null
  production_ML_framework: PyTorch
  task_category: LanguageModel
MC-189:
  card_name: Deep-OC-Sort SBS50
  dataset: Market1501ReIdDataset
  git_commit: 6bb51d027b137233f5c520b6fcc4f2ae387a6ba9
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 384, 128]
  key_metric: MOTA
  license: Apache-2.0
  model_repository: https://github.com/GerardMaggiolino/Deep-OC-SORT/
  model_subversion: null
  num_classes: 1
  onnx_model_path: ax_models/model_cards/torch/deep-oc-sort-sbs50-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/others/re-id/dance_sbs_S50.onnx
  onnx_yaml_description: (WIP) Deep-OC-Sort, MOT17 dataset, SBS50 for re-identification
  onnx_yaml_name: deep-oc-sort-sbs50-onnx
  production_ML_framework: PyTorch
  task_category: ReIdentification
MC-191:
  card_name: YOLOv10n
  dataset: CocoDataset-COCO2017
  git_commit: 6e43d1e1e5db72afbf686dee6745669bcb124b0a
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 640, 640]
  key_metric: mAP
  license: AGPL-3.0
  model_repository: https://github.com/ultralytics/ultralytics
  model_subversion: v8.3.0
  num_classes: 80
  onnx_model_path: ax_models/model_cards/yolo/object_detection/yolov10n-coco-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/yolo/object_detection/yolov10n.onnx
  onnx_yaml_description: yolov10n, 640x640 (COCO), anchor free model
  onnx_yaml_name: yolov10n-coco-onnx
  production_ML_framework: PyTorch
  task_category: ObjectDetection
MC-192:
  card_name: YOLOv10b
  dataset: CocoDataset-COCO2017
  git_commit: 6e43d1e1e5db72afbf686dee6745669bcb124b0a
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 640, 640]
  key_metric: mAP
  license: AGPL-3.0
  model_repository: https://github.com/ultralytics/ultralytics
  model_subversion: v8.3.0
  num_classes: 80
  onnx_model_path: ax_models/model_cards/yolo/object_detection/yolov10b-coco-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/yolo/object_detection/yolov10b.onnx
  onnx_yaml_description: yolov10b, 640x640 (COCO), anchor free model
  onnx_yaml_name: yolov10b-coco-onnx
  production_ML_framework: PyTorch
  task_category: ObjectDetection
MC-198:
  card_name: YOLOv8s-pose
  dataset: CocoDataset-keypoint-COCO2017
  git_commit: 0b7edb54544a245e3cb38bede156ffeda8e5d3d3
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 640, 640]
  key_metric: mAP
  license: AGPL-3.0
  model_repository: https://github.com/ultralytics/ultralytics
  model_subversion: v8.1.0
  native_ml_model_path: ax_models/model_cards/yolo/keypoint_detection/yolov8spose-coco.yaml
  native_ml_model_weight: https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8s-pose.pt
  native_ml_yaml_description: yolov8s pose estimation ultralytics v8.1.0, 640x640
    (COCO), native PyTorch model
  native_ml_yaml_name: yolov8spose-coco
  num_classes: 1
  onnx_model_path: ax_models/model_cards/yolo/keypoint_detection/yolov8spose-coco-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/yolo/keypoint_detection/yolov8s-pose-v8.1.onnx
  onnx_yaml_description: yolov8s pose estimation ultralytics v8.1.0, 640x640 (COCO)
  onnx_yaml_name: yolov8spose-coco-onnx
  production_ML_framework: PyTorch
  task_category: KeypointDetection
MC-199:
  card_name: YOLOv8l-pose
  dataset: CocoDataset-keypoint-COCO2017
  git_commit: 0b7edb54544a245e3cb38bede156ffeda8e5d3d3
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 640, 640]
  key_metric: mAP
  license: AGPL-3.0
  model_repository: https://github.com/ultralytics/ultralytics
  model_subversion: v8.1.0
  native_ml_model_path: ax_models/model_cards/yolo/keypoint_detection/yolov8lpose-coco.yaml
  native_ml_model_weight: https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8l-pose.pt
  native_ml_yaml_description: yolov8l pose estimation ultralytics v8.1.0, 640x640
    (COCO), native PyTorch model
  native_ml_yaml_name: yolov8lpose-coco
  num_classes: 1
  onnx_model_path: ax_models/model_cards/yolo/keypoint_detection/yolov8lpose-coco-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/yolo/keypoint_detection/yolov8l-pose-v8.1.onnx
  onnx_yaml_description: yolov8l pose estimation ultralytics v8.1.0, 640x640 (COCO)
  onnx_yaml_name: yolov8lpose-coco-onnx
  production_ML_framework: PyTorch
  task_category: KeypointDetection
MC-2:
  card_name: YOLOv5s-Relu
  dataset: CocoDataset-COCO2017
  git_commit: 8aa549c779e2b687dff56f9e27c026f0ad85a1bb
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 640, 640]
  key_metric: mAP
  license: AGPL-3.0
  model_repository: https://github.com/ultralytics/yolov5
  model_subversion: v5.0
  native_ml_model_path: ax_models/model_cards/yolo/object_detection/yolov5s-relu-coco.yaml
  native_ml_model_weight: s3://axelera-model-card/weights/yolo/object_detection/yolov5s-relu.pt
  native_ml_yaml_description: YOLOv5s-v5.0, ReLU, 640x640, S2D is replaced by a Conv
    operator (COCO)
  native_ml_yaml_name: yolov5s-relu-coco
  num_classes: 80
  onnx_model_path: ax_models/model_cards/yolo/object_detection/yolov5s-relu-coco-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/yolo/object_detection/yolov5s_relu.onnx
  onnx_yaml_description: YOLOv5s-v5.0, ReLU, 640x640, S2D on the host, AIPU input
    is 12x320x320 (COCO)
  onnx_yaml_name: yolov5s-relu-coco-onnx
  production_ML_framework: PyTorch
  task_category: ObjectDetection
MC-201:
  card_name: ResNet-10t 1*2456*2058
  dataset: ImageNet-1K
  git_commit: ce6a1d77e41bc75ba70d33fa40df6da49c0dff81
  input_color_format: GRAY
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 1, 2058, 2456]
  key_metric: Top1
  license: Apache 2.0
  model_repository: https://huggingface.co/timm/resnet10t.c3_in1k
  model_subversion: c3_in1k
  native_ml_model_path: ax_models/model_cards/timm/resnet10t-grayscale-imagenet.yaml
  native_ml_model_weight: ''
  native_ml_yaml_description: resnet10t.c3_in1k from timm, modified for grayscale
    and large input size
  native_ml_yaml_name: resnet10t-grayscale-imagenet
  num_classes: 1000
  production_ML_framework: PyTorch
  task_category: Classification
MC-203:
  card_name: CRNN-MobilenetV3-Large
  dataset: TextRecognitionDataset
  git_commit: 420ab32501ca1ff7d76c5c80e37a3a8ad6a1f89c
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 32, 128]
  key_metric: accuracy_mean
  license: Apache-2.0
  model_repository: https://github.com/mindee/doctr
  model_subversion: null
  num_classes: 1
  onnx_model_path: ax_models/model_cards/torch/crnn-mobilenetv3-large-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/app_weights/doctr/doctr_reco_crnn_mobilenet_v3_large.onnx
  onnx_yaml_description: (WIP) CRNN, MobilenetV3-Large, for text recognition
  onnx_yaml_name: crnn-mobilenetv3-large-onnx
  production_ML_framework: PyTorch
  task_category: OpticalCharacterRecognition
MC-221:
  card_name: MobileNetV4-small
  dataset: ImageNet-1K
  git_commit: a49b020effef7d3e8d6788adb32ab3faddf574a8
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 224, 224]
  key_metric: Top1
  license: Apache 2.0
  model_repository: https://github.com/huggingface/pytorch-image-models
  model_subversion: e2400_r224_in1k
  native_ml_model_path: ax_models/model_cards/timm/mobilenetv4_small-imagenet.yaml
  native_ml_model_weight: ''
  native_ml_yaml_description: mobilenetv4_conv_small.e2400_r224 from timm, https://huggingface.co/timm/mobilenetv4_conv_small.e2400_r224_in1k
  native_ml_yaml_name: mobilenetv4_small-imagenet
  num_classes: 1000
  onnx_model_path: ax_models/model_cards/timm/mobilenetv4_small-imagenet-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/classification/mobilenetv4_conv_small.e2400_r224_in1k.onnx
  onnx_yaml_description: mobilenetv4_conv_small.e2400_r224 from timm, converted as
    ONNX, https://huggingface.co/timm/mobilenetv4_conv_small.e2400_r224_in1k
  onnx_yaml_name: mobilenetv4_small-imagenet-onnx
  production_ML_framework: PyTorch
  task_category: Classification
MC-222:
  card_name: MobileNetV4-medium
  dataset: ImageNet-1K
  git_commit: a49b020effef7d3e8d6788adb32ab3faddf574a8
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 224, 224]
  key_metric: Top1
  license: Apache 2.0
  model_repository: https://github.com/huggingface/pytorch-image-models
  model_subversion: e500_r224_in1k
  native_ml_model_path: ax_models/model_cards/timm/mobilenetv4_medium-imagenet.yaml
  native_ml_model_weight: ''
  native_ml_yaml_description: mobilenetv4_conv_medium.e500_r224 from timm, https://huggingface.co/timm/mobilenetv4_conv_medium.e500_r224_in1k
  native_ml_yaml_name: mobilenetv4_medium-imagenet
  num_classes: 1000
  onnx_model_path: ax_models/model_cards/timm/mobilenetv4_medium-imagenet-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/classification/mobilenetv4_conv_medium.e500_r224_in1k.onnx
  onnx_yaml_description: mobilenetv4_conv_medium.e500_r224 from timm, converted as
    ONNX, https://huggingface.co/timm/mobilenetv4_conv_medium.e500_r224_in1k
  onnx_yaml_name: mobilenetv4_medium-imagenet-onnx
  production_ML_framework: PyTorch
  task_category: Classification
MC-223:
  card_name: MobileNetV4-large
  dataset: ImageNet-1K
  git_commit: a49b020effef7d3e8d6788adb32ab3faddf574a8
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 384, 384]
  key_metric: Top1
  license: Apache 2.0
  model_repository: https://github.com/huggingface/pytorch-image-models
  model_subversion: e600_r384_in1k
  native_ml_model_path: ax_models/model_cards/timm/mobilenetv4_large-imagenet.yaml
  native_ml_model_weight: ''
  native_ml_yaml_description: mobilenetv4_conv_large.e600_r384_in1k from timm, https://huggingface.co/timm/mobilenetv4_conv_large.e600_r384_in1k
  native_ml_yaml_name: mobilenetv4_large-imagenet
  num_classes: 1000
  onnx_model_path: ax_models/model_cards/timm/mobilenetv4_large-imagenet-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/classification/mobilenetv4_conv_large.e600_r384_in1k.onnx
  onnx_yaml_description: mobilenetv4_conv_large.e600_r384_in1k from timm, converted
    as ONNX, https://huggingface.co/timm/mobilenetv4_conv_large.e600_r384_in1k
  onnx_yaml_name: mobilenetv4_large-imagenet-onnx
  production_ML_framework: PyTorch
  task_category: Classification
MC-224:
  card_name: MobileNetV4-aa_large
  dataset: ImageNet-1K
  git_commit: a49b020effef7d3e8d6788adb32ab3faddf574a8
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 384, 384]
  key_metric: Top1
  license: Apache 2.0
  model_repository: https://github.com/huggingface/pytorch-image-models
  model_subversion: e600_r384_in1k
  native_ml_model_path: ax_models/model_cards/timm/mobilenetv4_aa_large-imagenet.yaml
  native_ml_model_weight: ''
  native_ml_yaml_description: mobilenetv4_conv_aa_large.e600_r384_in1k from timm,
    https://huggingface.co/timm/mobilenetv4_conv_aa_large.e600_r384_in1k
  native_ml_yaml_name: mobilenetv4_aa_large-imagenet
  num_classes: 1000
  onnx_model_path: ax_models/model_cards/timm/mobilenetv4_aa_large-imagenet-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/classification/mobilenetv4_conv_aa_large.e600_r384_in1k.onnx
  onnx_yaml_description: mobilenetv4_conv_aa_large.e600_r384_in1k from timm, converted
    as ONNX, https://huggingface.co/timm/mobilenetv4_conv_aa_large.e600_r384_in1k
  onnx_yaml_name: mobilenetv4_aa_large-imagenet-onnx
  production_ML_framework: PyTorch
  task_category: Classification
MC-225:
  card_name: FastDepth
  dataset: NYUDepthV2
  git_commit: c695d853318da3b20a2fa26d8251ed00d4b3ef20
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 224, 224]
  key_metric: RMSE
  license: MIT
  model_repository: https://github.com/PINTO0309/PINTO_model_zoo/tree/main/146_FastDepth
  model_subversion: null
  num_classes: 1
  onnx_model_path: ax_models/model_cards/torch/fastdepth-nyudepthv2-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/depth_estimation/fast_depth_224x224.onnx
  onnx_yaml_description: FastDepth with NYU Depth V2 dataset
  onnx_yaml_name: fastdepth-nyudepthv2-onnx
  production_ML_framework: PyTorch
  task_category: DepthEstimation
MC-227:
  card_name: YOLOv9t
  dataset: CocoDataset-COCO2017
  git_commit: 6e43d1e1e5db72afbf686dee6745669bcb124b0a
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 640, 640]
  key_metric: mAP
  license: AGPL-3.0
  model_repository: https://github.com/ultralytics/ultralytics
  model_subversion: v8.3.0
  num_classes: 80
  onnx_model_path: ax_models/model_cards/yolo/object_detection/yolov9t-coco-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/yolo/object_detection/yolov9t-8.3-dynamic.onnx
  onnx_yaml_description: yolov9t, 640x640 (COCO), anchor free model
  onnx_yaml_name: yolov9t-coco-onnx
  production_ML_framework: PyTorch
  task_category: ObjectDetection
MC-228:
  card_name: YOLOv9s
  dataset: CocoDataset-COCO2017
  git_commit: 6e43d1e1e5db72afbf686dee6745669bcb124b0a
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 640, 640]
  key_metric: mAP
  license: AGPL-3.0
  model_repository: https://github.com/ultralytics/ultralytics
  model_subversion: v8.3.0
  num_classes: 80
  onnx_model_path: ax_models/model_cards/yolo/object_detection/yolov9s-coco-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/yolo/object_detection/yolov9s-8.3-dynamic.onnx
  onnx_yaml_description: yolov9s, 640x640 (COCO), anchor free model
  onnx_yaml_name: yolov9s-coco-onnx
  production_ML_framework: PyTorch
  task_category: ObjectDetection
MC-229:
  card_name: YOLOv9m
  dataset: CocoDataset-COCO2017
  git_commit: 6e43d1e1e5db72afbf686dee6745669bcb124b0a
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 640, 640]
  key_metric: mAP
  license: AGPL-3.0
  model_repository: https://github.com/ultralytics/ultralytics
  model_subversion: v8.3.0
  num_classes: 80
  onnx_model_path: ax_models/model_cards/yolo/object_detection/yolov9m-coco-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/yolo/object_detection/yolov9m-8.3-dynamic.onnx
  onnx_yaml_description: yolov9m, 640x640 (COCO), anchor free model
  onnx_yaml_name: yolov9m-coco-onnx
  production_ML_framework: PyTorch
  task_category: ObjectDetection
MC-23:
  card_name: SSD-MobileNetV2
  dataset: CocoDataset-COCO2017
  git_commit: 2a00ddbb0bfc857da946c1780bbd65eb662c2119
  input_color_format: RGB
  input_tensor_layout: NHWC
  input_tensor_shape: [1, 300, 300, 3]
  key_metric: mAP
  license: Apache 2.0
  model_repository: https://github.com/tensorflow/models
  model_subversion: v2.15.0
  num_classes: 90
  onnx_model_path: ax_models/model_cards/tensorflow/object_detection/ssd-mobilenetv2-coco-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/object_detection/tf2_ssd-mbv2.onnx
  onnx_yaml_description: SSD-Mobilenetv2 (COCO) trained from tensorflow2 and converted
    as ONNX
  onnx_yaml_name: ssd-mobilenetv2-coco-onnx
  poc_onnx_input_tensor_layout: NCHW
  poc_onnx_input_tensor_shape: [1, 3, 300, 300]
  poc_onnx_model_path: ax_models/model_cards/tensorflow/object_detection/ssd-mobilenetv2-coco-poc-onnx.yaml
  poc_onnx_model_weight: s3://axelera-model-card/weights/object_detection/manual_clean/extracted_ssd_mbnetv2_final.onnx
  poc_onnx_yaml_description: SSD-Mobilenetv2 (COCO) trained from tensorflow2 and converted
    as ONNX, manually edited to PoC. We will fully support it later.
  poc_onnx_yaml_name: ssd-mobilenetv2-coco-poc-onnx
  production_ML_framework: Tensorflow2
  task_category: ObjectDetection
MC-24:
  card_name: RetinaFace - mb0.25
  dataset: WiderFace
  git_commit: b984b4b775b2c4dced95c1eadd195a5c7d32a60b
  input_color_format: BGR
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 640, 640]
  key_metric: mAP
  license: MIT
  model_repository: https://github.com/biubug6/Pytorch_Retinaface/tree/master
  model_subversion: N/A
  num_classes: 1
  onnx_model_path: ax_models/model_cards/torch/retinaface-mobilenet0.25-widerface-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/others/object_detection/Retinaface_mb0.25_pytorch.onnx
  onnx_yaml_description: RetinaFace face detection and landmark localization model
    trained on WiderFace dataset with MobileNet0.25 backbone
  onnx_yaml_name: retinaface-mobilenet0.25-widerface-onnx
  production_ML_framework: PyTorch
  task_category: ObjectDetection
MC-246:
  card_name: ResNet-10t
  dataset: ImageNet-1K
  git_commit: ce6a1d77e41bc75ba70d33fa40df6da49c0dff81
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 224, 224]
  key_metric: Top1
  license: Apache 2.0
  model_repository: https://huggingface.co/timm/resnet10t.c3_in1k
  model_subversion: c3_in1k
  native_ml_model_path: ax_models/model_cards/timm/resnet10t-imagenet.yaml
  native_ml_model_weight: ''
  native_ml_yaml_description: resnet10t.c3_in1k from timm
  native_ml_yaml_name: resnet10t-imagenet
  num_classes: 1000
  onnx_model_path: ax_models/model_cards/timm/resnet10t-imagenet-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/classification/resnet10t.onnx
  onnx_yaml_description: resnet10t.c3_in1k from timm, converted as ONNX
  onnx_yaml_name: resnet10t-imagenet-onnx
  production_ML_framework: PyTorch
  task_category: Classification
MC-249:
  card_name: U-Net FCN 256
  dataset: Cityscapes
  git_commit: c685fe6767c4cadf6b051983ca6208f1b9d1ccb8
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 256, 256]
  key_metric: mIoU
  license: Apache 2.0
  model_repository: https://github.com/open-mmlab/mmsegmentation/tree/main/configs/unet
  model_subversion: v1.2.2
  num_classes: 19
  onnx_model_path: ax_models/model_cards/mmlab/mmseg/unet_fcn_256-cityscapes-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/mmlab/semantic_segmentation/unet_fcn_dynamic.onnx
  onnx_yaml_description: U-Net FCN from MMSegmentation, ONNX with dynamic axes, 256x256
    input
  onnx_yaml_name: unet_fcn_256-cityscapes-onnx
  production_ML_framework: PyTorch
  task_category: SemanticSegmentation
MC-250:
  card_name: U-Net FCN 512
  dataset: Cityscapes
  git_commit: c685fe6767c4cadf6b051983ca6208f1b9d1ccb8
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 512, 512]
  key_metric: mIoU
  license: Apache 2.0
  model_repository: https://github.com/open-mmlab/mmsegmentation/tree/main/configs/unet
  model_subversion: v1.2.2
  native_ml_model_path: ax_models/model_cards/mmlab/mmseg/unet_fcn_512-cityscapes.yaml
  native_ml_model_weight: s3://axelera-model-card/weights/mmlab/semantic_segmentation/fcn_unet_s5-d16_4x4_512x1024_160k_cityscapes_20211210_145204-6860854e.pth
  native_ml_yaml_description: U-Net FCN from MMSegmentation with 512x512 input size
  native_ml_yaml_name: unet_fcn_512-cityscapes
  num_classes: 19
  production_ML_framework: PyTorch
  task_category: SemanticSegmentation
MC-256:
  card_name: YOLO11n
  dataset: CocoDataset-COCO2017
  git_commit: 6e43d1e1e5db72afbf686dee6745669bcb124b0a
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 640, 640]
  key_metric: mAP
  license: AGPL-3.0
  model_repository: https://github.com/ultralytics/ultralytics
  model_subversion: v8.3.0
  native_ml_model_path: ax_models/model_cards/yolo/object_detection/yolo11n-coco.yaml
  native_ml_model_weight: https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt
  native_ml_yaml_description: (WIP) yolo11n, 640x640 (COCO), anchor free model, native
    PyTorch model
  native_ml_yaml_name: yolo11n-coco
  num_classes: 80
  onnx_model_path: ax_models/model_cards/yolo/object_detection/yolo11n-coco-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/yolo/object_detection/yolo11n.onnx
  onnx_yaml_description: yolo11n, 640x640 (COCO), anchor free model
  onnx_yaml_name: yolo11n-coco-onnx
  production_ML_framework: PyTorch
  task_category: ObjectDetection
MC-257:
  card_name: YOLO11s
  dataset: CocoDataset-COCO2017
  git_commit: 6e43d1e1e5db72afbf686dee6745669bcb124b0a
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 640, 640]
  key_metric: mAP
  license: AGPL-3.0
  model_repository: https://github.com/ultralytics/ultralytics
  model_subversion: v8.3.0
  native_ml_model_path: ax_models/model_cards/yolo/object_detection/yolo11s-coco.yaml
  native_ml_model_weight: https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11s.pt
  native_ml_yaml_description: (WIP) yolo11s, 640x640 (COCO), anchor free model, native
    PyTorch model
  native_ml_yaml_name: yolo11s-coco
  num_classes: 80
  onnx_model_path: ax_models/model_cards/yolo/object_detection/yolo11s-coco-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/yolo/object_detection/yolo11s.onnx
  onnx_yaml_description: yolo11s, 640x640 (COCO), anchor free model
  onnx_yaml_name: yolo11s-coco-onnx
  production_ML_framework: PyTorch
  task_category: ObjectDetection
MC-258:
  card_name: YOLO11m
  dataset: CocoDataset-COCO2017
  git_commit: 6e43d1e1e5db72afbf686dee6745669bcb124b0a
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 640, 640]
  key_metric: mAP
  license: AGPL-3.0
  model_repository: https://github.com/ultralytics/ultralytics
  model_subversion: v8.3.0
  native_ml_model_path: ax_models/model_cards/yolo/object_detection/yolo11m-coco.yaml
  native_ml_model_weight: https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11m.pt
  native_ml_yaml_description: (WIP) yolo11m, 640x640 (COCO), anchor free model, native
    PyTorch model
  native_ml_yaml_name: yolo11m-coco
  num_classes: 80
  onnx_model_path: ax_models/model_cards/yolo/object_detection/yolo11m-coco-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/yolo/object_detection/yolo11m.onnx
  onnx_yaml_description: yolo11m, 640x640 (COCO), anchor free model
  onnx_yaml_name: yolo11m-coco-onnx
  production_ML_framework: PyTorch
  task_category: ObjectDetection
MC-259:
  card_name: YOLO11l
  dataset: CocoDataset-COCO2017
  git_commit: 6e43d1e1e5db72afbf686dee6745669bcb124b0a
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 640, 640]
  key_metric: mAP
  license: AGPL-3.0
  model_repository: https://github.com/ultralytics/ultralytics
  model_subversion: v8.3.0
  native_ml_model_path: ax_models/model_cards/yolo/object_detection/yolo11l-coco.yaml
  native_ml_model_weight: https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11l.pt
  native_ml_yaml_description: (WIP) yolo11l, 640x640 (COCO), anchor free model, native
    PyTorch model
  native_ml_yaml_name: yolo11l-coco
  num_classes: 80
  onnx_model_path: ax_models/model_cards/yolo/object_detection/yolo11l-coco-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/yolo/object_detection/yolo11l.onnx
  onnx_yaml_description: yolo11l, 640x640 (COCO), anchor free model
  onnx_yaml_name: yolo11l-coco-onnx
  production_ML_framework: PyTorch
  task_category: ObjectDetection
MC-260:
  card_name: YOLO11x
  dataset: CocoDataset-COCO2017
  git_commit: 6e43d1e1e5db72afbf686dee6745669bcb124b0a
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 640, 640]
  key_metric: mAP
  license: AGPL-3.0
  model_repository: https://github.com/ultralytics/ultralytics
  model_subversion: v8.3.0
  native_ml_model_path: ax_models/model_cards/yolo/object_detection/yolo11x-coco.yaml
  native_ml_model_weight: https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11x.pt
  native_ml_yaml_description: (WIP) yolo11x, 640x640 (COCO), anchor free model, native
    PyTorch model
  native_ml_yaml_name: yolo11x-coco
  num_classes: 80
  onnx_model_path: ax_models/model_cards/yolo/object_detection/yolo11x-coco-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/yolo/object_detection/yolo11x.onnx
  onnx_yaml_description: yolo11x, 640x640 (COCO), anchor free model
  onnx_yaml_name: yolo11x-coco-onnx
  production_ML_framework: PyTorch
  task_category: ObjectDetection
MC-261:
  card_name: YOLO11n-seg
  dataset: CocoDataset-Segment-COCO2017
  git_commit: 6e43d1e1e5db72afbf686dee6745669bcb124b0a
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 640, 640]
  key_metric: mAP
  license: AGPL-3.0
  model_repository: https://github.com/ultralytics/ultralytics
  model_subversion: v8.3.0
  native_ml_model_path: ax_models/model_cards/yolo/instance_segmentation/yolo11nseg-coco.yaml
  native_ml_model_weight: https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n-seg.pt
  native_ml_yaml_description: (WIP)yolo11n seg estimation ultralytics v8.3.0, 640x640
    (COCO), native PyTorch model
  native_ml_yaml_name: yolo11nseg-coco
  num_classes: 80
  onnx_model_path: ax_models/model_cards/yolo/instance_segmentation/yolo11nseg-coco-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/yolo/instance_segmentation/yolo11n-seg.onnx
  onnx_yaml_description: yolo11n seg estimation ultralytics v8.3.0, 640x640 (COCO)
  onnx_yaml_name: yolo11nseg-coco-onnx
  production_ML_framework: PyTorch
  task_category: InstanceSegmentation
MC-262:
  card_name: YOLO11l-seg
  dataset: CocoDataset-Segment-COCO2017
  git_commit: 6e43d1e1e5db72afbf686dee6745669bcb124b0a
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 640, 640]
  key_metric: mAP
  license: AGPL-3.0
  model_repository: https://github.com/ultralytics/ultralytics
  model_subversion: v8.3.0
  native_ml_model_path: ax_models/model_cards/yolo/instance_segmentation/yolo11lseg-coco.yaml
  native_ml_model_weight: https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11l-seg.pt
  native_ml_yaml_description: (WIP) yolo11l seg estimation ultralytics v8.3.0, 640x640
    (COCO), native PyTorch model
  native_ml_yaml_name: yolo11lseg-coco
  num_classes: 80
  onnx_model_path: ax_models/model_cards/yolo/instance_segmentation/yolo11lseg-coco-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/yolo/instance_segmentation/yolo11l-seg.onnx
  onnx_yaml_description: (WIP) yolo11l seg estimation ultralytics v8.3.0, 640x640
    (COCO)
  onnx_yaml_name: yolo11lseg-coco-onnx
  production_ML_framework: PyTorch
  task_category: InstanceSegmentation
MC-263:
  card_name: YOLO11n-pose
  dataset: CocoDataset-keypoint-COCO2017
  git_commit: 6e43d1e1e5db72afbf686dee6745669bcb124b0a
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 640, 640]
  key_metric: mAP
  license: AGPL-3.0
  model_repository: https://github.com/ultralytics/ultralytics
  model_subversion: v8.3.0
  native_ml_model_path: ax_models/model_cards/yolo/keypoint_detection/yolo11npose-coco.yaml
  native_ml_model_weight: https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n-pose.pt
  native_ml_yaml_description: (WIP) yolo11n pose estimation ultralytics v8.3.0, 640x640
    (COCO), native PyTorch model
  native_ml_yaml_name: yolo11npose-coco
  num_classes: 1
  onnx_model_path: ax_models/model_cards/yolo/keypoint_detection/yolo11npose-coco-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/yolo/keypoint_detection/yolo11n-pose.onnx
  onnx_yaml_description: yolo11n pose estimation ultralytics v8.3.0, 640x640 (COCO)
  onnx_yaml_name: yolo11npose-coco-onnx
  production_ML_framework: PyTorch
  task_category: KeypointDetection
MC-264:
  card_name: YOLO11l-pose
  dataset: CocoDataset-keypoint-COCO2017
  git_commit: 6e43d1e1e5db72afbf686dee6745669bcb124b0a
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 640, 640]
  key_metric: mAP
  license: AGPL-3.0
  model_repository: https://github.com/ultralytics/ultralytics
  model_subversion: v8.3.0
  native_ml_model_path: ax_models/model_cards/yolo/keypoint_detection/yolo11lpose-coco.yaml
  native_ml_model_weight: https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11l-pose.pt
  native_ml_yaml_description: (WIP) yolo11l pose estimation ultralytics v8.3.0, 640x640
    (COCO), native PyTorch model
  native_ml_yaml_name: yolo11lpose-coco
  num_classes: 1
  onnx_model_path: ax_models/model_cards/yolo/keypoint_detection/yolo11lpose-coco-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/yolo/keypoint_detection/yolo11l-pose.onnx
  onnx_yaml_description: (WIP) yolo11l pose estimation ultralytics v8.3.0, 640x640
    (COCO)
  onnx_yaml_name: yolo11lpose-coco-onnx
  production_ML_framework: PyTorch
  task_category: KeypointDetection
MC-271:
  card_name: Real-ESRGAN-x4plus
  dataset: SuperResolutionCustomSet128x128
  git_commit: a4abfb2979a7bbff3f69f58f58ae324608821e27
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 128, 128]
  key_metric: PSNR
  license: BSD-3-Clause
  model_repository: https://github.com/xinntao/Real-ESRGAN
  model_subversion: x4plus
  num_classes: 1
  onnx_model_path: ax_models/model_cards/torch/real-esrgan-x4plus-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/image_enhancement/superresolution/RealESRGAN_x4plus.onnx
  onnx_yaml_description: Real-ESRGAN-x4plus super resolution model, converted as ONNX
  onnx_yaml_name: real-esrgan-x4plus-onnx
  production_ML_framework: PyTorch
  task_category: ImageEnhancementSuperResolution
MC-274:
  card_name: Llama-3.1-8B (1024)
  dataset: ''
  git_commit: null
  icdf_model_path: ax_models/model_cards/llm/llama-3-1-8b-1024-4core-static.yaml
  icdf_model_weight: https://llm.axelera.ai/icdf/4.x/llama8b_1024_mc_model.tar.gz
  icdf_yaml_description: HuggingFace Transformers Llama-3.1-8B-Instruct model, limiting
    the sequence length to 1024 tokens, compiled for 4 cores execution
  icdf_yaml_name: llama-3-1-8b-1024-4core-static
  input_color_format: null
  input_tensor_layout: null
  input_tensor_shape: null
  key_metric: LLM
  license: Llama 3.1 Community License Agreement
  model_repository: https://huggingface.co/meta-llama/Llama-3.1-8B
  model_subversion: 4core
  num_classes: null
  production_ML_framework: PyTorch
  task_category: LanguageModel
MC-275:
  card_name: Llama-3.2-1B (1024)
  dataset: ''
  git_commit: null
  icdf_model_path: ax_models/model_cards/llm/llama-3-2-1b-1024-4core-static.yaml
  icdf_model_weight: https://llm.axelera.ai/icdf/4.x/llama1b_1024_mc_model.tar.gz
  icdf_yaml_description: HuggingFace Transformers Llama-3.2-1B-Instruct model, limiting
    the sequence length to 1024 tokens, compiled for 4 cores execution
  icdf_yaml_name: llama-3-2-1b-1024-4core-static
  input_color_format: null
  input_tensor_layout: null
  input_tensor_shape: null
  key_metric: LLM
  license: Llama 3.2 Community License Agreement
  model_repository: https://huggingface.co/meta-llama/Llama-3.2-1B
  model_subversion: 4core
  num_classes: null
  production_ML_framework: PyTorch
  task_category: LanguageModel
MC-276:
  card_name: Llama-3.2-3B
  dataset: ''
  git_commit: null
  icdf_model_path: ax_models/model_cards/llm/llama-3-2-3b-1024-4core-static.yaml
  icdf_model_weight: https://llm.axelera.ai/icdf/4.x/llama3b_1024_mc_model.tar.gz
  icdf_yaml_description: HuggingFace Transformers Llama-3.2-3B-Instruct model, limiting
    the sequence length to 1024 tokens, compiled for 4 cores execution
  icdf_yaml_name: llama-3-2-3b-1024-4core-static
  input_color_format: null
  input_tensor_layout: null
  input_tensor_shape: null
  key_metric: LLM
  license: Llama 3.2 Community License Agreement
  model_repository: https://huggingface.co/meta-llama/Llama-3.2-3B
  model_subversion: 4core
  num_classes: null
  production_ML_framework: PyTorch
  task_category: LanguageModel
MC-278:
  card_name: OSNet x1_0
  dataset: Market1501ReIdDataset
  git_commit: 566a56a2cb255f59ba75aa817032621784df546a
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 256, 128]
  key_metric: mAP
  license: Apache-2.0
  model_repository: https://github.com/KaiyangZhou/deep-person-reid
  model_subversion: null
  num_classes: 1
  onnx_model_path: ax_models/model_cards/torch/osnet-x1-0-market1501-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/others/re-id/osnet_x1_0_market.onnx
  onnx_yaml_description: This is a osnet_x1_0_market_256x128_amsgrad_ep150_stp60_lr0.0015_b64_fb10_softmax_labelsmooth_flip.pth
    model trained on market1501 dataset from https://kaiyangzhou.github.io/deep-person-reid/MODEL_ZOO#imagenet-pretrained-models
    and converted to onnx.
  onnx_yaml_name: osnet-x1-0-market1501-onnx
  production_ML_framework: PyTorch
  task_category: ReIdentification
MC-281:
  card_name: Axelera-YOLOv8l
  dataset: CocoDataset-COCO2017
  git_commit: null
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 640, 640]
  key_metric: mAP
  license: AGPL-3.0
  model_repository: null
  model_subversion: null
  num_classes: 80
  onnx_model_path: ax_models/model_cards/yolo/object_detection/ax-yolov8l-coco-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/ax_models/pruned/AxeleraYolov8l_acc5310.onnx
  onnx_yaml_description: Axelera optimized YOLOv8l model (in-house pruned model),
    contact us if you are interested in the model
  onnx_yaml_name: ax-yolov8l-coco-onnx
  production_ML_framework: PyTorch
  task_category: ObjectDetection
MC-282:
  card_name: Axelera-YOLOv8m
  dataset: CocoDataset-COCO2017
  git_commit: null
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 640, 640]
  key_metric: mAP
  license: AGPL-3.0
  model_repository: null
  model_subversion: null
  num_classes: 80
  onnx_model_path: ax_models/model_cards/yolo/object_detection/ax-yolov8m-coco-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/ax_models/pruned/AxeleraYolov8m_acc5190.onnx
  onnx_yaml_description: Axelera optimized YOLOv8m model (in-house pruned model),
    contact us if you are interested in the model
  onnx_yaml_name: ax-yolov8m-coco-onnx
  production_ML_framework: PyTorch
  task_category: ObjectDetection
MC-283:
  card_name: Axelera-YOLOv8m-Lite
  dataset: CocoDataset-COCO2017
  git_commit: null
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 640, 640]
  key_metric: mAP
  license: AGPL-3.0
  model_repository: null
  model_subversion: null
  num_classes: 80
  onnx_model_path: ax_models/model_cards/yolo/object_detection/ax-yolov8m-lite-coco-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/ax_models/pruned/AxeleraYolov8mLite_acc4990_latency8ms.onnx
  onnx_yaml_description: Axelera optimized YOLOv8m Lite model (in-house pruned model),
    contact us if you are interested in the model
  onnx_yaml_name: ax-yolov8m-lite-coco-onnx
  production_ML_framework: PyTorch
  task_category: ObjectDetection
MC-284:
  card_name: Axelera-YOLOv8s
  dataset: CocoDataset-COCO2017
  git_commit: null
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 640, 640]
  key_metric: mAP
  license: AGPL-3.0
  model_repository: null
  model_subversion: null
  num_classes: 80
  onnx_model_path: ax_models/model_cards/yolo/object_detection/ax-yolov8s-coco-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/ax_models/pruned/AxeleraYolov8s_acc4690.onnx
  onnx_yaml_description: Axelera optimized YOLOv8s model (in-house pruned model),
    contact us if you are interested in the model
  onnx_yaml_name: ax-yolov8s-coco-onnx
  production_ML_framework: PyTorch
  task_category: ObjectDetection
MC-285:
  card_name: Axelera-YOLOv8n
  dataset: CocoDataset-COCO2017
  git_commit: null
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 640, 640]
  key_metric: mAP
  license: AGPL-3.0
  model_repository: null
  model_subversion: null
  num_classes: 80
  onnx_model_path: ax_models/model_cards/yolo/object_detection/ax-yolov8n-coco-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/ax_models/pruned/AxeleraYolov8n_acc4267.onnx
  onnx_yaml_description: Axelera optimized YOLOv8n model (in-house pruned model),
    contact us if you are interested in the model
  onnx_yaml_name: ax-yolov8n-coco-onnx
  production_ML_framework: PyTorch
  task_category: ObjectDetection
MC-29:
  card_name: SSD-MobileNetV1
  dataset: CocoDataset-COCO2017
  git_commit: unknown
  input_color_format: RGB
  key_metric: mAP
  license: Apache 2.0
  model_repository: http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_coco_2018_01_28.tar.gz
  model_subversion: unknown
  num_classes: 90
  poc_onnx_input_tensor_layout: NCHW
  poc_onnx_input_tensor_shape: [1, 3, 300, 300]
  poc_onnx_model_path: ax_models/model_cards/tensorflow/object_detection/ssd-mobilenetv1-coco-poc-onnx.yaml
  poc_onnx_model_weight: s3://axelera-model-card/weights/object_detection/manual_clean/ssd300_mobilenet_v1_modified_valid.onnx
  poc_onnx_yaml_description: SSD300-MobileNetv1 (COCO) trained from tensorflow1 and
    converted as ONNX, manually edited to PoC. We will fully support it later.
  poc_onnx_yaml_name: ssd-mobilenetv1-coco-poc-onnx
  production_ML_framework: Tensorflow
  task_category: ObjectDetection
MC-292:
  card_name: Velvet-2B
  dataset: ''
  git_commit: null
  icdf_model_path: ax_models/model_cards/llm/velvet-2b-1024-4core-static.yaml
  icdf_model_weight: https://llm.axelera.ai/icdf/4.x/velvet2b_1024_mc_model.tar.gz
  icdf_yaml_description: HuggingFace Transformers Velvet-2B model, limiting the sequence
    length to 1024 tokens, compiled for 4 cores execution
  icdf_yaml_name: velvet-2b-1024-4core-static
  input_color_format: null
  input_tensor_layout: null
  input_tensor_shape: null
  key_metric: LLM
  license: Apache 2.0
  model_repository: https://huggingface.co/Almawave/Velvet-2B
  model_subversion: 4core
  num_classes: null
  production_ML_framework: PyTorch
  task_category: LanguageModel
MC-293:
  card_name: YOLOv8xpose-p6
  dataset: CocoDataset-keypoint-COCO2017
  git_commit: e1d742500fbfc24a08c4eb664d0111eaffc8827a
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 1280, 1280]
  key_metric: mAP
  license: AGPL-3.0
  model_repository: https://github.com/ultralytics/ultralytics
  model_subversion: v8.3.0
  native_ml_model_path: ax_models/model_cards/yolo/keypoint_detection/yolov8xpose-p6-coco.yaml
  native_ml_model_weight: https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8x-pose-p6.pt
  native_ml_yaml_description: yolov8l-p6 pose estimation ultralytics v8.3.0, 1280x1280
    (COCO), native PyTorch model
  native_ml_yaml_name: yolov8xpose-p6-coco
  num_classes: 1
  onnx_model_path: ax_models/model_cards/yolo/keypoint_detection/yolov8xpose-p6-coco-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/yolo/keypoint_detection/yolov8x-pose-p6.onnx
  onnx_yaml_description: yolov8xpose-p6 pose estimation ultralytics v8.3.0, 1280x1280
    (COCO)
  onnx_yaml_name: yolov8xpose-p6-coco-onnx
  production_ML_framework: PyTorch
  task_category: KeypointDetection
MC-297:
  card_name: Phi3-mini (1024)
  dataset: ''
  git_commit: null
  icdf_model_path: ax_models/model_cards/llm/phi3-mini-1024-4core-static.yaml
  icdf_model_weight: https://llm.axelera.ai/icdf/4.x/phi3_1024_mc_model.tar.gz
  icdf_yaml_description: HuggingFace Transformers Phi-3-mini-4k-instruct model, limiting
    the sequence length to 1024 tokens, compiled for 4 cores execution
  icdf_yaml_name: phi3-mini-1024-4core-static
  input_color_format: null
  input_tensor_layout: null
  input_tensor_shape: null
  key_metric: LLM
  license: MIT
  model_repository: https://huggingface.co/microsoft/Phi-3-mini-4k-instruct
  model_subversion: 4core
  num_classes: null
  production_ML_framework: PyTorch
  task_category: LanguageModel
MC-298:
  card_name: Phi3-mini (512)
  dataset: ''
  git_commit: null
  icdf_model_path: ax_models/model_cards/llm/phi3-mini-512-static.yaml
  icdf_model_weight: https://llm.axelera.ai/icdf/4.x/phi3_512_model.tar.gz
  icdf_yaml_description: HuggingFace Transformers Phi-3-mini-4k-instruct model, limiting
    the sequence length to 512 tokens. This model is statically compiled by using
    Axelera R&D tools.
  icdf_yaml_name: phi3-mini-512-static
  input_color_format: null
  input_tensor_layout: null
  input_tensor_shape: null
  key_metric: LLM
  license: MIT
  model_repository: https://huggingface.co/microsoft/Phi-3-mini-4k-instruct
  model_subversion: null
  num_classes: null
  production_ML_framework: PyTorch
  task_category: LanguageModel
MC-3:
  card_name: YOLOv7
  dataset: CocoDataset-COCO2017
  git_commit: a207844b1ce82d204ab36d87d496728d3d2348e7
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 640, 640]
  key_metric: mAP
  license: GPL-3.0
  model_repository: https://github.com/WongKinYiu/yolov7
  model_subversion: v0.1
  native_ml_model_path: ax_models/model_cards/yolo/object_detection/yolov7-coco.yaml
  native_ml_model_weight: s3://axelera-model-card/weights/yolo/object_detection/yolov7.pt
  native_ml_yaml_description: YOLOv7 640x640 (COCO)
  native_ml_yaml_name: yolov7-coco
  num_classes: 80
  onnx_model_path: ax_models/model_cards/yolo/object_detection/yolov7-coco-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/yolo/object_detection/yolov7.onnx
  onnx_yaml_description: YOLOv7-v0.1 ONNX (COCO)
  onnx_yaml_name: yolov7-coco-onnx
  production_ML_framework: PyTorch
  task_category: ObjectDetection
MC-30:
  card_name: SqueezeNet 1.0
  dataset: ImageNet-1K
  git_commit: bddbd7e6d65ecacc2e40cf6c9e2059669b8dbd44
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 224, 224]
  key_metric: Top1
  license: BSD-3-Clause
  model_repository: https://github.com/pytorch/vision
  model_subversion: v0.13.1
  native_ml_model_path: ax_models/model_cards/torchvision/classification/squeezenet1.0-imagenet.yaml
  native_ml_model_weight: ''
  native_ml_yaml_description: SqueezeNet 1.0 (ImageNet)
  native_ml_yaml_name: squeezenet1.0-imagenet
  num_classes: 1000
  onnx_model_path: ax_models/model_cards/torchvision/classification/squeezenet1.0-imagenet-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/classification/squeezenet1_0_pretrained.onnx
  onnx_yaml_description: squeezenet1.0 (ImageNet) trained from torchvision and converted
    as ONNX
  onnx_yaml_name: squeezenet1.0-imagenet-onnx
  production_ML_framework: PyTorch
  task_category: Classification
MC-302:
  card_name: YOLOv10s
  dataset: CocoDataset-COCO2017
  git_commit: 6e43d1e1e5db72afbf686dee6745669bcb124b0a
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 640, 640]
  key_metric: mAP
  license: AGPL-3.0
  model_repository: https://github.com/ultralytics/ultralytics
  model_subversion: v8.3.0
  num_classes: 80
  onnx_model_path: ax_models/model_cards/yolo/object_detection/yolov10s-coco-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/yolo/object_detection/yolov10s.onnx
  onnx_yaml_description: yolov10s, 640x640 (COCO), anchor free model
  onnx_yaml_name: yolov10s-coco-onnx
  production_ML_framework: PyTorch
  task_category: ObjectDetection
MC-303:
  card_name: DINOv2-DPT Depth
  dataset: NYUDepthV2
  git_commit: 5776fdeb81586a1563c9a4414d47e4156b3ea9b1
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 224, 224]
  key_metric: RMSE
  license: MIT
  model_repository: https://huggingface.co/facebook/dpt-dinov2-base-nyu
  model_subversion: null
  num_classes: 1
  onnx_model_path: ax_models/model_cards/torch/dinov2-depth-nyudepth2-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/depth_estimation/dpt-dinov2-base-nyu_224x224.onnx
  onnx_yaml_description: DPT (Dense Prediction Transformer) model with DINOv2 backbone
    as proposed in DINOv2 Learning Robust Visual Features without Supervision by Oquab
    et al.
  onnx_yaml_name: dinov2-depth-nyudepth2-onnx
  production_ML_framework: PyTorch
  task_category: DepthEstimation
MC-308:
  card_name: YOLO11n-obb
  dataset: DOTAv1DetectionOBBDataset
  git_commit: c7c7c139dc5585cd2fd3e110d7010cc74b0c0589
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 1024, 1024]
  key_metric: mAP
  license: AGPL-3.0
  model_repository: https://github.com/ultralytics/ultralytics
  model_subversion: N/A
  num_classes: 15
  onnx_model_path: ax_models/model_cards/yolo/obb_detection/yolo11n-obb-dotav1-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/yolo/object_detection/yolo11n-obb-ultralytics.onnx
  onnx_yaml_description: YOLO11n-obb ultralytics converted from https://github.com/ultralytics/ultralytics
  onnx_yaml_name: yolo11n-obb-dotav1-onnx
  production_ML_framework: PyTorch
  task_category: ObjectDetection
MC-309:
  card_name: YOLOv8n-obb
  dataset: DOTAv1DetectionOBBDataset
  git_commit: c7c7c139dc5585cd2fd3e110d7010cc74b0c0589
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 1024, 1024]
  key_metric: mAP
  license: AGPL-3.0
  model_repository: https://github.com/ultralytics/ultralytics
  model_subversion: N/A
  num_classes: 15
  onnx_model_path: ax_models/model_cards/yolo/obb_detection/yolov8n-obb-dotav1-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/yolo/object_detection/yolov8n-obb.onnx
  onnx_yaml_description: YOLOv8n-obb ultralytics converted from https://github.com/ultralytics/ultralytics
  onnx_yaml_name: yolov8n-obb-dotav1-onnx
  production_ML_framework: PyTorch
  task_category: ObjectDetection
MC-31:
  card_name: ResNet-34
  dataset: ImageNet-1K
  git_commit: bddbd7e6d65ecacc2e40cf6c9e2059669b8dbd44
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 224, 224]
  key_metric: Top1
  license: BSD-3-Clause
  model_repository: https://github.com/pytorch/vision
  model_subversion: v0.13.1
  native_ml_model_path: ax_models/model_cards/torchvision/classification/resnet34-imagenet.yaml
  native_ml_model_weight: ''
  native_ml_yaml_description: ResNet 34 (ImageNet) - v1.5 from torchvision
  native_ml_yaml_name: resnet34-imagenet
  num_classes: 1000
  onnx_model_path: ax_models/model_cards/torchvision/classification/resnet34-imagenet-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/classification/resnet34_pretrained.onnx
  onnx_yaml_description: resnet34 (ImageNet) trained from torchvision and converted
    as ONNX
  onnx_yaml_name: resnet34-imagenet-onnx
  production_ML_framework: PyTorch
  task_category: Classification
MC-314:
  card_name: YOLOX-x Human
  dataset: CocoDataset-COCO2017
  git_commit: d1bf0191adff59bc8fcfeaa0b33d3d1642552a99
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 800, 1440]
  key_metric: mAP
  license: MIT
  model_repository: https://github.com/FoundationVision/ByteTrack
  model_subversion: N/A
  num_classes: 1
  onnx_model_path: ax_models/model_cards/yolo/object_detection/yolox-x-crowdhuman-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/yolo/object_detection/bytetrack_ablation.onnx
  onnx_yaml_description: YOLOX-x trained on CrowdHuman and MOT17 half train set from
    ByteTrack
  onnx_yaml_name: yolox-x-crowdhuman-onnx
  production_ML_framework: PyTorch
  task_category: ObjectDetection
MC-315:
  card_name: YOLO26n
  dataset: CocoDataset-COCO2017
  git_commit: 85eacfca734e57918816e7f9e1c9dc5a15127c25
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 640, 640]
  key_metric: mAP
  license: AGPL-3.0
  model_repository: https://github.com/ultralytics/ultralytics
  model_subversion: v8.3.204
  num_classes: 80
  onnx_model_path: ax_models/model_cards/yolo/object_detection/yolo26n-coco-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/yolo/object_detection/yolo26n-preview-1001.onnx
  onnx_yaml_description: yolo26n, 640x640 (COCO), NMS free model
  onnx_yaml_name: yolo26n-coco-onnx
  production_ML_framework: PyTorch
  task_category: ObjectDetection
MC-316:
  card_name: YOLO26s
  dataset: CocoDataset-COCO2017
  git_commit: 85eacfca734e57918816e7f9e1c9dc5a15127c25
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 640, 640]
  key_metric: mAP
  license: AGPL-3.0
  model_repository: https://github.com/ultralytics/ultralytics
  model_subversion: v8.3.204
  num_classes: 80
  onnx_model_path: ax_models/model_cards/yolo/object_detection/yolo26s-coco-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/yolo/object_detection/yolo26s-preview-1001.onnx
  onnx_yaml_description: yolo26s, 640x640 (COCO), NMS free model
  onnx_yaml_name: yolo26s-coco-onnx
  production_ML_framework: PyTorch
  task_category: ObjectDetection
MC-317:
  card_name: YOLO26m
  dataset: CocoDataset-COCO2017
  git_commit: 85eacfca734e57918816e7f9e1c9dc5a15127c25
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 640, 640]
  key_metric: mAP
  license: AGPL-3.0
  model_repository: https://github.com/ultralytics/ultralytics
  model_subversion: v8.3.204
  num_classes: 80
  onnx_model_path: ax_models/model_cards/yolo/object_detection/yolo26m-coco-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/yolo/object_detection/yolo26m-preview-1001.onnx
  onnx_yaml_description: yolo26m, 640x640 (COCO), NMS free model
  onnx_yaml_name: yolo26m-coco-onnx
  production_ML_framework: PyTorch
  task_category: ObjectDetection
MC-318:
  card_name: YOLO26l
  dataset: CocoDataset-COCO2017
  git_commit: 85eacfca734e57918816e7f9e1c9dc5a15127c25
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 640, 640]
  key_metric: mAP
  license: AGPL-3.0
  model_repository: https://github.com/ultralytics/ultralytics
  model_subversion: v8.3.204
  num_classes: 80
  onnx_model_path: ax_models/model_cards/yolo/object_detection/yolo26l-coco-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/yolo/object_detection/yolo26l-preview-1001.onnx
  onnx_yaml_description: yolo26l, 640x640 (COCO), NMS free model
  onnx_yaml_name: yolo26l-coco-onnx
  production_ML_framework: PyTorch
  task_category: ObjectDetection
MC-319:
  card_name: YOLO26x
  dataset: CocoDataset-COCO2017
  git_commit: 85eacfca734e57918816e7f9e1c9dc5a15127c25
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 640, 640]
  key_metric: mAP
  license: AGPL-3.0
  model_repository: https://github.com/ultralytics/ultralytics
  model_subversion: v8.3.204
  num_classes: 80
  onnx_model_path: ax_models/model_cards/yolo/object_detection/yolo26x-coco-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/yolo/object_detection/yolo26x-preview-1001.onnx
  onnx_yaml_description: yolo26x, 640x640 (COCO), NMS free model
  onnx_yaml_name: yolo26x-coco-onnx
  production_ML_framework: PyTorch
  task_category: ObjectDetection
MC-32:
  card_name: ResNet-50 v1.5
  dataset: ImageNet-1K
  git_commit: bddbd7e6d65ecacc2e40cf6c9e2059669b8dbd44
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 224, 224]
  key_metric: Top1
  license: BSD-3-Clause
  model_repository: https://github.com/pytorch/vision
  model_subversion: v0.13.1
  native_ml_model_path: ax_models/model_cards/torchvision/classification/resnet50-imagenet.yaml
  native_ml_model_weight: ''
  native_ml_yaml_description: ResNet 50 (ImageNet) - v1.5 from torchvision
  native_ml_yaml_name: resnet50-imagenet
  num_classes: 1000
  onnx_model_path: ax_models/model_cards/torchvision/classification/resnet50-imagenet-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/classification/resnet50_pretrained.onnx
  onnx_yaml_description: resnet50 (ImageNet) trained from torchvision and converted
    as ONNX
  onnx_yaml_name: resnet50-imagenet-onnx
  production_ML_framework: PyTorch
  task_category: Classification
MC-320:
  card_name: YOLO11l-obb
  dataset: DOTAv1DetectionOBBDataset
  git_commit: c7c7c139dc5585cd2fd3e110d7010cc74b0c0589
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 1024, 1024]
  key_metric: mAP
  license: AGPL-3.0
  model_repository: https://github.com/ultralytics/ultralytics
  model_subversion: N/A
  num_classes: 15
  onnx_model_path: ax_models/model_cards/yolo/obb_detection/yolo11l-obb-dotav1-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/yolo/object_detection/yolo11l-obb.onnx
  onnx_yaml_description: YOLO11l-obb ultralytics converted from https://github.com/ultralytics/ultralytics
  onnx_yaml_name: yolo11l-obb-dotav1-onnx
  production_ML_framework: PyTorch
  task_category: ObjectDetection
MC-321:
  card_name: YOLOv8l-obb
  dataset: DOTAv1DetectionOBBDataset
  git_commit: c7c7c139dc5585cd2fd3e110d7010cc74b0c0589
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 1024, 1024]
  key_metric: mAP
  license: AGPL-3.0
  model_repository: https://github.com/ultralytics/ultralytics
  model_subversion: N/A
  num_classes: 15
  onnx_model_path: ax_models/model_cards/yolo/obb_detection/yolov8l-obb-dotav1-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/yolo/object_detection/yolov8l-obb.onnx
  onnx_yaml_description: YOLOv8l-obb ultralytics converted from https://github.com/ultralytics/ultralytics
  onnx_yaml_name: yolov8l-obb-dotav1-onnx
  production_ML_framework: PyTorch
  task_category: ObjectDetection
MC-33:
  card_name: YOLOv5s
  dataset: CocoDataset-COCO2017
  git_commit: 915bbf294bb74c859f0b41f1c23bc395014ea679
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 640, 640]
  key_metric: mAP
  license: AGPL-3.0
  model_repository: https://github.com/ultralytics/yolov5
  model_subversion: v7.0
  native_ml_model_path: ax_models/model_cards/yolo/object_detection/yolov5s-v7-coco.yaml
  native_ml_model_weight: s3://axelera-model-card/weights/yolo/object_detection/yolov5s.pt
  native_ml_yaml_description: YOLOv5s-v7.0, SiLU, 640x640 (COCO)
  native_ml_yaml_name: yolov5s-v7-coco
  num_classes: 80
  onnx_model_path: ax_models/model_cards/yolo/object_detection/yolov5s-v7-coco-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/yolo/object_detection/yolov5s-v7.onnx
  onnx_yaml_description: YOLOv5s-v7.0 ONNX, SiLU, 640x640 (COCO)
  onnx_yaml_name: yolov5s-v7-coco-onnx
  production_ML_framework: PyTorch
  task_category: ObjectDetection
MC-34:
  card_name: YOLOv5m
  dataset: CocoDataset-COCO2017
  git_commit: 915bbf294bb74c859f0b41f1c23bc395014ea679
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 640, 640]
  key_metric: mAP
  license: AGPL-3.0
  model_repository: https://github.com/ultralytics/yolov5
  model_subversion: v7.0
  native_ml_model_path: ax_models/model_cards/yolo/object_detection/yolov5m-v7-coco.yaml
  native_ml_model_weight: s3://axelera-model-card/weights/yolo/object_detection/yolov5m.pt
  native_ml_yaml_description: YOLOv5m-v7.0, SiLU, 640x640 (COCO)
  native_ml_yaml_name: yolov5m-v7-coco
  num_classes: 80
  onnx_model_path: ax_models/model_cards/yolo/object_detection/yolov5m-v7-coco-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/yolo/object_detection/yolov5m-v7.onnx
  onnx_yaml_description: YOLOv5m-v7.0 ONNX, SiLU, 640x640 (COCO)
  onnx_yaml_name: yolov5m-v7-coco-onnx
  production_ML_framework: PyTorch
  task_category: ObjectDetection
MC-35:
  card_name: YOLOv5l
  dataset: CocoDataset-COCO2017
  git_commit: 915bbf294bb74c859f0b41f1c23bc395014ea679
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 640, 640]
  key_metric: mAP
  license: AGPL-3.0
  model_repository: https://github.com/ultralytics/yolov5
  model_subversion: v7.0
  native_ml_model_path: ax_models/model_cards/yolo/object_detection/yolov5l-v7-coco.yaml
  native_ml_model_weight: s3://axelera-model-card/weights/yolo/object_detection/yolov5l.pt
  native_ml_yaml_description: YOLOv5l-v7.0, SiLU, 640x640 (COCO)
  native_ml_yaml_name: yolov5l-v7-coco
  num_classes: 80
  onnx_model_path: ax_models/model_cards/yolo/object_detection/yolov5l-v7-coco-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/yolo/object_detection/yolov5l-v7.onnx
  onnx_yaml_description: YOLOv5l-v7.0 ONNX, SiLU, 640x640 (COCO)
  onnx_yaml_name: yolov5l-v7-coco-onnx
  production_ML_framework: PyTorch
  task_category: ObjectDetection
MC-36:
  card_name: MobileNetV2
  dataset: ImageNet-1K
  git_commit: bddbd7e6d65ecacc2e40cf6c9e2059669b8dbd44
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 224, 224]
  key_metric: Top1
  license: BSD-3-Clause
  model_repository: https://github.com/pytorch/vision
  model_subversion: v0.13.1
  native_ml_model_path: ax_models/model_cards/torchvision/classification/mobilenetv2-imagenet.yaml
  native_ml_model_weight: ''
  native_ml_yaml_description: mobilenetv2 (ImageNet) from torchvision
  native_ml_yaml_name: mobilenetv2-imagenet
  num_classes: 1000
  onnx_model_path: ax_models/model_cards/torchvision/classification/mobilenetv2-imagenet-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/classification/mobilenet_v2_pretrained.onnx
  onnx_yaml_description: mobilenetv2 (ImageNet) trained from torchvision and converted
    as ONNX
  onnx_yaml_name: mobilenetv2-imagenet-onnx
  production_ML_framework: PyTorch
  task_category: Classification
MC-39:
  card_name: YOLOv3
  dataset: CocoDataset-COCO2017
  git_commit: 8b0abddfeed13c6523708c69aa373a22a1c25871
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 640, 640]
  key_metric: mAP
  license: AGPL-3.0
  model_repository: https://github.com/ultralytics/yolov3
  model_subversion: v9.6.0
  num_classes: 80
  onnx_model_path: ax_models/model_cards/yolo/object_detection/yolov3-coco-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/yolo/object_detection/yolov3.onnx
  onnx_yaml_description: yolov3 ultralytics v9.6.0, input size 640x640 (COCO)
  onnx_yaml_name: yolov3-coco-onnx
  production_ML_framework: PyTorch
  task_category: ObjectDetection
MC-43:
  card_name: MobileNetV3-small
  dataset: ImageNet-1K
  git_commit: bddbd7e6d65ecacc2e40cf6c9e2059669b8dbd44
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 224, 224]
  key_metric: Top1
  license: BSD-3-Clause
  model_repository: https://github.com/pytorch/vision
  model_subversion: v0.13.1
  native_ml_model_path: ax_models/model_cards/torchvision/classification/mobilenetv3_small-imagenet.yaml
  native_ml_model_weight: ''
  native_ml_yaml_description: mobilenetv3_small (ImageNet) from torchvision
  native_ml_yaml_name: mobilenetv3_small-imagenet
  num_classes: 1000
  onnx_model_path: ax_models/model_cards/torchvision/classification/mobilenetv3_small-imagenet-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/classification/mobilenet_v3_small_pretrained.onnx
  onnx_yaml_description: mobilenetv3_small (ImageNet) trained from torchvision and
    converted as ONNX
  onnx_yaml_name: mobilenetv3_small-imagenet-onnx
  production_ML_framework: PyTorch
  task_category: Classification
MC-49:
  card_name: YOLO-NAS M
  dataset: CocoDataset-COCO2017
  git_commit: 15315f8cc6a834864a62ef620609ab5e3a4b56b0
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 640, 640]
  key_metric: mAP
  license: Apache-2.0
  model_repository: https://github.com/Deci-AI/super-gradients
  model_subversion: v3.6.0
  num_classes: 80
  onnx_model_path: ax_models/model_cards/yolo/object_detection/yolonas-m-coco-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/yolo/object_detection/yolo_nas_m.onnx
  onnx_yaml_description: YOLONAS-m ONNX, 640x640 (COCO), anchor free model
  onnx_yaml_name: yolonas-m-coco-onnx
  production_ML_framework: PyTorch
  task_category: ObjectDetection
MC-50:
  card_name: YOLOv8l
  dataset: CocoDataset-COCO2017
  git_commit: 0b7edb54544a245e3cb38bede156ffeda8e5d3d3
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 640, 640]
  key_metric: mAP
  license: AGPL-3.0
  model_repository: https://github.com/ultralytics/ultralytics
  model_subversion: v8.1.0
  native_ml_model_path: ax_models/model_cards/yolo/object_detection/yolov8l-coco.yaml
  native_ml_model_weight: https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8l.pt
  native_ml_yaml_description: yolov8l ultralytics v8.3.0, 640x640 (COCO), anchor free
    model, native PyTorch model
  native_ml_yaml_name: yolov8l-coco
  num_classes: 80
  onnx_model_path: ax_models/model_cards/yolo/object_detection/yolov8l-coco-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/yolo/object_detection/yolov8l_ultralytics_v8.1.0.onnx
  onnx_yaml_description: yolov8l ultralytics v8.1.0, 640x640 (COCO), anchor free model
  onnx_yaml_name: yolov8l-coco-onnx
  production_ML_framework: PyTorch
  task_category: ObjectDetection
MC-51:
  card_name: YOLOv7-W6
  dataset: CocoDataset-COCO2017
  git_commit: a207844b1ce82d204ab36d87d496728d3d2348e7
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 1280, 1280]
  key_metric: mAP
  license: GPL-3.0
  model_repository: https://github.com/WongKinYiu/yolov7
  model_subversion: v0.1
  native_ml_model_path: ax_models/model_cards/yolo/object_detection/yolov7-w6-coco.yaml
  native_ml_model_weight: s3://axelera-model-card/weights/yolo/object_detection/yolov7-w6.pt
  native_ml_yaml_description: YOLOv7w6 1280x1280 (COCO)
  native_ml_yaml_name: yolov7-w6-coco
  num_classes: 80
  onnx_model_path: ax_models/model_cards/yolo/object_detection/yolov7-w6-coco-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/yolo/object_detection/yolov7-w6.onnx
  onnx_yaml_description: YOLOv7-w6-v0.1 ONNX (COCO)
  onnx_yaml_name: yolov7-w6-coco-onnx
  production_ML_framework: PyTorch
  task_category: ObjectDetection
MC-52:
  card_name: YOLOv7-tiny
  dataset: CocoDataset-COCO2017
  git_commit: a207844b1ce82d204ab36d87d496728d3d2348e7
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 416, 416]
  key_metric: mAP
  license: GPL-3.0
  model_repository: https://github.com/WongKinYiu/yolov7
  model_subversion: v0.1
  native_ml_model_path: ax_models/model_cards/yolo/object_detection/yolov7-tiny-coco.yaml
  native_ml_model_weight: s3://axelera-model-card/weights/yolo/object_detection/yolov7-tiny.pt
  native_ml_yaml_description: YOLOv7-tiny 640x640 (COCO)
  native_ml_yaml_name: yolov7-tiny-coco
  num_classes: 80
  onnx_model_path: ax_models/model_cards/yolo/object_detection/yolov7-tiny-coco-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/yolo/object_detection/yolov7-tiny.onnx
  onnx_yaml_description: YOLOv7-tiny-v0.1 ONNX (COCO)
  onnx_yaml_name: yolov7-tiny-coco-onnx
  production_ML_framework: PyTorch
  task_category: ObjectDetection
MC-53:
  card_name: YOLOv5n
  dataset: CocoDataset-COCO2017
  git_commit: 915bbf294bb74c859f0b41f1c23bc395014ea679
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 640, 640]
  key_metric: mAP
  license: AGPL-3.0
  model_repository: https://github.com/ultralytics/yolov5
  model_subversion: v7.0
  native_ml_model_path: ax_models/model_cards/yolo/object_detection/yolov5n-v7-coco.yaml
  native_ml_model_weight: s3://axelera-model-card/weights/yolo/object_detection/yolov5n.pt
  native_ml_yaml_description: YOLOv5n-v7.0, SiLU, 640x640 (COCO)
  native_ml_yaml_name: yolov5n-v7-coco
  num_classes: 80
  onnx_model_path: ax_models/model_cards/yolo/object_detection/yolov5n-v7-coco-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/yolo/object_detection/yolov5n-v7.onnx
  onnx_yaml_description: YOLOv5n-v7.0 ONNX, SiLU, 640x640 (COCO)
  onnx_yaml_name: yolov5n-v7-coco-onnx
  production_ML_framework: PyTorch
  task_category: ObjectDetection
MC-54:
  card_name: YOLOX-m
  dataset: CocoDataset-COCO2017
  git_commit: ac58e0a5e68e57454b7b9ac822aced493b553c53
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 640, 640]
  key_metric: mAP
  license: Apache-2.0
  model_repository: https://github.com/Megvii-BaseDetection/YOLOX
  model_subversion: v0.3.0
  num_classes: 80
  onnx_model_path: ax_models/model_cards/yolo/object_detection/yolox-m-coco-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/yolo/object_detection/yolox_m.onnx
  onnx_yaml_description: YOLOX-m v0.3.0, ONNX with preprocessed Focus layer, input
    size 640x640 (COCO), anchor free model
  onnx_yaml_name: yolox-m-coco-onnx
  production_ML_framework: PyTorch
  task_category: ObjectDetection
MC-6:
  card_name: YOLOv8s
  dataset: CocoDataset-COCO2017
  git_commit: 0b7edb54544a245e3cb38bede156ffeda8e5d3d3
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 640, 640]
  key_metric: mAP
  license: AGPL-3.0
  model_repository: https://github.com/ultralytics/ultralytics
  model_subversion: v8.1.0
  native_ml_model_path: ax_models/model_cards/yolo/object_detection/yolov8s-coco.yaml
  native_ml_model_weight: https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8s.pt
  native_ml_yaml_description: yolov8s ultralytics v8.3.0, 640x640 (COCO), anchor free
    model, native PyTorch model
  native_ml_yaml_name: yolov8s-coco
  num_classes: 80
  onnx_model_path: ax_models/model_cards/yolo/object_detection/yolov8s-coco-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/yolo/object_detection/yolov8s_ultralytics_v8.1.0.onnx
  onnx_yaml_description: yolov8s ultralytics v8.1.0, 640x640 (COCO), anchor free model
  onnx_yaml_name: yolov8s-coco-onnx
  production_ML_framework: PyTorch
  task_category: ObjectDetection
MC-69:
  card_name: ConvNeXT base
  dataset: ImageNet-1K
  git_commit: bddbd7e6d65ecacc2e40cf6c9e2059669b8dbd44
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 224, 224]
  key_metric: Top1
  license: BSD-3-Clause
  model_repository: https://github.com/pytorch/vision
  model_subversion: v0.13.1
  native_ml_model_path: ax_models/model_cards/torchvision/classification/convnext_base-imagenet.yaml
  native_ml_model_weight: ''
  native_ml_yaml_description: ConvNextBase (ImageNet) - v1.5 from torchvision
  native_ml_yaml_name: convnext_base-imagenet
  num_classes: 1000
  onnx_model_path: ax_models/model_cards/torchvision/classification/convnext_base-imagenet-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/classification/convnext_base_17.onnx
  onnx_yaml_description: ConvNextBase (ImageNet) trained from torchvision and converted
    as ONNX
  onnx_yaml_name: convnext_base-imagenet-onnx
  production_ML_framework: PyTorch
  task_category: Classification
MC-7:
  card_name: YOLOv8m
  dataset: CocoDataset-COCO2017
  git_commit: 0b7edb54544a245e3cb38bede156ffeda8e5d3d3
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 640, 640]
  key_metric: mAP
  license: AGPL-3.0
  model_repository: https://github.com/ultralytics/ultralytics
  model_subversion: v8.1.0
  native_ml_model_path: ax_models/model_cards/yolo/object_detection/yolov8m-coco.yaml
  native_ml_model_weight: https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8m.pt
  native_ml_yaml_description: yolov8m ultralytics v8.3.0, 640x640 (COCO), anchor free
    model, native PyTorch model
  native_ml_yaml_name: yolov8m-coco
  num_classes: 80
  onnx_model_path: ax_models/model_cards/yolo/object_detection/yolov8m-coco-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/yolo/object_detection/yolov8m_ultralytics_v8.1.0.onnx
  onnx_yaml_description: yolov8m ultralytics v8.1.0, 640x640 (COCO), anchor free model
  onnx_yaml_name: yolov8m-coco-onnx
  production_ML_framework: PyTorch
  task_category: ObjectDetection
MC-70:
  card_name: ConvNeXT large
  dataset: ImageNet-1K
  git_commit: bddbd7e6d65ecacc2e40cf6c9e2059669b8dbd44
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 224, 224]
  key_metric: Top1
  license: BSD-3-Clause
  model_repository: https://github.com/pytorch/vision
  model_subversion: v0.13.1
  native_ml_model_path: ax_models/model_cards/torchvision/classification/convnext_large-imagenet.yaml
  native_ml_model_weight: ''
  native_ml_yaml_description: ConvNextLarge (ImageNet) - v1.5 from torchvision
  native_ml_yaml_name: convnext_large-imagenet
  num_classes: 1000
  onnx_model_path: ax_models/model_cards/torchvision/classification/convnext_large-imagenet-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/classification/convnext_large_17.onnx
  onnx_yaml_description: ConvNextLarge (ImageNet) trained from torchvision and converted
    as ONNX
  onnx_yaml_name: convnext_large-imagenet-onnx
  production_ML_framework: PyTorch
  task_category: Classification
MC-71:
  card_name: ConvNeXT tiny
  dataset: ImageNet-1K
  git_commit: bddbd7e6d65ecacc2e40cf6c9e2059669b8dbd44
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 224, 224]
  key_metric: Top1
  license: BSD-3-Clause
  model_repository: https://github.com/pytorch/vision
  model_subversion: v0.13.1
  native_ml_model_path: ax_models/model_cards/torchvision/classification/convnext_tiny-imagenet.yaml
  native_ml_model_weight: ''
  native_ml_yaml_description: ConvNextTiny (ImageNet) - v1.5 from torchvision
  native_ml_yaml_name: convnext_tiny-imagenet
  num_classes: 1000
  onnx_model_path: ax_models/model_cards/torchvision/classification/convnext_tiny-imagenet-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/classification/convnext_tiny_17.onnx
  onnx_yaml_description: ConvNextTiny (ImageNet) trained from torchvision and converted
    as ONNX
  onnx_yaml_name: convnext_tiny-imagenet-onnx
  production_ML_framework: PyTorch
  task_category: Classification
MC-72:
  card_name: ConvNeXT small
  dataset: ImageNet-1K
  git_commit: bddbd7e6d65ecacc2e40cf6c9e2059669b8dbd44
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 224, 224]
  key_metric: Top1
  license: BSD-3-Clause
  model_repository: https://github.com/pytorch/vision
  model_subversion: v0.13.1
  native_ml_model_path: ax_models/model_cards/torchvision/classification/convnext_small-imagenet.yaml
  native_ml_model_weight: ''
  native_ml_yaml_description: ConvNextSmall (ImageNet) - v1.5 from torchvision
  native_ml_yaml_name: convnext_small-imagenet
  num_classes: 1000
  onnx_model_path: ax_models/model_cards/torchvision/classification/convnext_small-imagenet-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/classification/convnext_small_17.onnx
  onnx_yaml_description: ConvNextSmall (ImageNet) trained from torchvision and converted
    as ONNX
  onnx_yaml_name: convnext_small-imagenet-onnx
  production_ML_framework: PyTorch
  task_category: Classification
MC-73:
  card_name: EfficientNet-B0
  dataset: ImageNet-1K
  git_commit: bddbd7e6d65ecacc2e40cf6c9e2059669b8dbd44
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 224, 224]
  key_metric: Top1
  license: BSD-3-Clause
  model_repository: https://github.com/pytorch/vision
  model_subversion: v0.13.1
  native_ml_model_path: ax_models/model_cards/torchvision/classification/efficientnet_b0-imagenet.yaml
  native_ml_model_weight: ''
  native_ml_yaml_description: EfficientNet_B0 (ImageNet) - v1.5 from torchvision
  native_ml_yaml_name: efficientnet_b0-imagenet
  num_classes: 1000
  onnx_model_path: ax_models/model_cards/torchvision/classification/efficientnet_b0-imagenet-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/classification/efficientnet_b0_pretrained.onnx
  onnx_yaml_description: EfficientNet_B0 (ImageNet) trained from torchvision and converted
    as ONNX
  onnx_yaml_name: efficientnet_b0-imagenet-onnx
  production_ML_framework: PyTorch
  task_category: Classification
MC-74:
  card_name: EfficientNet-B1
  dataset: ImageNet-1K
  git_commit: bddbd7e6d65ecacc2e40cf6c9e2059669b8dbd44
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 224, 224]
  key_metric: Top1
  license: BSD-3-Clause
  model_repository: https://github.com/pytorch/vision
  model_subversion: v0.13.1
  native_ml_model_path: ax_models/model_cards/torchvision/classification/efficientnet_b1-imagenet.yaml
  native_ml_model_weight: ''
  native_ml_yaml_description: EfficientNet_B1 (ImageNet) - v1.5 from torchvision
  native_ml_yaml_name: efficientnet_b1-imagenet
  num_classes: 1000
  onnx_model_path: ax_models/model_cards/torchvision/classification/efficientnet_b1-imagenet-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/classification/efficientnet_b1_pretrained.onnx
  onnx_yaml_description: EfficientNet_B1 (ImageNet) trained from torchvision and converted
    as ONNX
  onnx_yaml_name: efficientnet_b1-imagenet-onnx
  production_ML_framework: PyTorch
  task_category: Classification
MC-75:
  card_name: EfficientNet-B2
  dataset: ImageNet-1K
  git_commit: bddbd7e6d65ecacc2e40cf6c9e2059669b8dbd44
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 224, 224]
  key_metric: Top1
  license: BSD-3-Clause
  model_repository: https://github.com/pytorch/vision
  model_subversion: v0.13.1
  native_ml_model_path: ax_models/model_cards/torchvision/classification/efficientnet_b2-imagenet.yaml
  native_ml_model_weight: ''
  native_ml_yaml_description: EfficientNet_B2 (ImageNet) - v1.5 from torchvision
  native_ml_yaml_name: efficientnet_b2-imagenet
  num_classes: 1000
  onnx_model_path: ax_models/model_cards/torchvision/classification/efficientnet_b2-imagenet-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/classification/efficientnet_b2_pretrained.onnx
  onnx_yaml_description: EfficientNet_B2 (ImageNet) trained from torchvision and converted
    as ONNX
  onnx_yaml_name: efficientnet_b2-imagenet-onnx
  production_ML_framework: PyTorch
  task_category: Classification
MC-76:
  card_name: EfficientNet-B3
  dataset: ImageNet-1K
  git_commit: bddbd7e6d65ecacc2e40cf6c9e2059669b8dbd44
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 224, 224]
  key_metric: Top1
  license: BSD-3-Clause
  model_repository: https://github.com/pytorch/vision
  model_subversion: v0.13.1
  native_ml_model_path: ax_models/model_cards/torchvision/classification/efficientnet_b3-imagenet.yaml
  native_ml_model_weight: ''
  native_ml_yaml_description: EfficientNet_B3 (ImageNet) - v1.5 from torchvision
  native_ml_yaml_name: efficientnet_b3-imagenet
  num_classes: 1000
  onnx_model_path: ax_models/model_cards/torchvision/classification/efficientnet_b3-imagenet-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/classification/efficientnet_b3_pretrained.onnx
  onnx_yaml_description: EfficientNet_B3 (ImageNet) trained from torchvision and converted
    as ONNX
  onnx_yaml_name: efficientnet_b3-imagenet-onnx
  production_ML_framework: PyTorch
  task_category: Classification
MC-77:
  card_name: EfficientNet-B4
  dataset: ImageNet-1K
  git_commit: bddbd7e6d65ecacc2e40cf6c9e2059669b8dbd44
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 224, 224]
  key_metric: Top1
  license: BSD-3-Clause
  model_repository: https://github.com/pytorch/vision
  model_subversion: v0.13.1
  native_ml_model_path: ax_models/model_cards/torchvision/classification/efficientnet_b4-imagenet.yaml
  native_ml_model_weight: ''
  native_ml_yaml_description: EfficientNet_B4 (ImageNet) - v1.5 from torchvision
  native_ml_yaml_name: efficientnet_b4-imagenet
  num_classes: 1000
  onnx_model_path: ax_models/model_cards/torchvision/classification/efficientnet_b4-imagenet-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/classification/efficientnet_b4.onnx
  onnx_yaml_description: EfficientNet_B4 (ImageNet) trained from torchvision and converted
    as ONNX
  onnx_yaml_name: efficientnet_b4-imagenet-onnx
  production_ML_framework: PyTorch
  task_category: Classification
MC-8:
  card_name: YOLO-NAS S
  dataset: CocoDataset-COCO2017
  git_commit: 15315f8cc6a834864a62ef620609ab5e3a4b56b0
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 640, 640]
  key_metric: mAP
  license: Apache-2.0
  model_repository: https://github.com/Deci-AI/super-gradients
  model_subversion: v3.6.0
  num_classes: 80
  onnx_model_path: ax_models/model_cards/yolo/object_detection/yolonas-s-coco-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/yolo/object_detection/yolo_nas_s.onnx
  onnx_yaml_description: YOLONAS-s ONNX, 640x640 (COCO), anchor free model
  onnx_yaml_name: yolonas-s-coco-onnx
  production_ML_framework: PyTorch
  task_category: ObjectDetection
MC-80:
  card_name: YOLO-NAS L
  dataset: CocoDataset-COCO2017
  git_commit: 15315f8cc6a834864a62ef620609ab5e3a4b56b0
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 640, 640]
  key_metric: mAP
  license: Apache-2.0
  model_repository: https://github.com/Deci-AI/super-gradients
  model_subversion: v3.6.0
  num_classes: 80
  onnx_model_path: ax_models/model_cards/yolo/object_detection/yolonas-l-coco-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/yolo/object_detection/yolo_nas_l.onnx
  onnx_yaml_description: YOLONAS-l ONNX, 640x640 (COCO), anchor free model
  onnx_yaml_name: yolonas-l-coco-onnx
  production_ML_framework: PyTorch
  task_category: ObjectDetection
MC-84:
  card_name: ResNeXt50_32x4d
  dataset: ImageNet-1K
  git_commit: bddbd7e6d65ecacc2e40cf6c9e2059669b8dbd44
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 224, 224]
  key_metric: Top1
  license: BSD-3-Clause
  model_repository: https://github.com/pytorch/vision
  model_subversion: v0.13.1
  native_ml_model_path: ax_models/model_cards/torchvision/classification/resnext50_32x4d-imagenet.yaml
  native_ml_model_weight: ''
  native_ml_yaml_description: ResNeXt50_32x4d (ImageNet) - v1.5 from torchvision
  native_ml_yaml_name: resnext50_32x4d-imagenet
  num_classes: 1000
  onnx_model_path: ax_models/model_cards/torchvision/classification/resnext50_32x4d-imagenet-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/classification/resnext50_32x4d_pretrained.onnx
  onnx_yaml_description: ResNeXt50_32x4d (ImageNet) trained from torchvision and converted
    as ONNX
  onnx_yaml_name: resnext50_32x4d-imagenet-onnx
  production_ML_framework: PyTorch
  task_category: Classification
MC-86:
  card_name: RegNetX-1_6GF
  dataset: ImageNet-1K
  git_commit: bddbd7e6d65ecacc2e40cf6c9e2059669b8dbd44
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 224, 224]
  key_metric: Top1
  license: BSD-3-Clause
  model_repository: https://github.com/pytorch/vision
  model_subversion: v0.13.1
  native_ml_model_path: ax_models/model_cards/torchvision/classification/regnet_x_1_6gf-imagenet.yaml
  native_ml_model_weight: ''
  native_ml_yaml_description: RegNetX-1_6GF (ImageNet) - v1.5 from torchvision
  native_ml_yaml_name: regnet_x_1_6gf-imagenet
  num_classes: 1000
  onnx_model_path: ax_models/model_cards/torchvision/classification/regnet_x_1_6gf-imagenet-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/classification/regnet_x_1_6gf_pretrained.onnx
  onnx_yaml_description: RegNetX-1_6GF (ImageNet) trained from torchvision and converted
    as ONNX
  onnx_yaml_name: regnet_x_1_6gf-imagenet-onnx
  production_ML_framework: PyTorch
  task_category: Classification
MC-89:
  card_name: RegNetX-400MF
  dataset: ImageNet-1K
  git_commit: bddbd7e6d65ecacc2e40cf6c9e2059669b8dbd44
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 224, 224]
  key_metric: Top1
  license: BSD-3-Clause
  model_repository: https://github.com/pytorch/vision
  model_subversion: v0.13.1
  native_ml_model_path: ax_models/model_cards/torchvision/classification/regnet_x_400mf-imagenet.yaml
  native_ml_model_weight: ''
  native_ml_yaml_description: RegNet_X_400MF (ImageNet) - v1.5 from torchvision
  native_ml_yaml_name: regnet_x_400mf-imagenet
  num_classes: 1000
  onnx_model_path: ax_models/model_cards/torchvision/classification/regnet_x_400mf-imagenet-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/classification/regnet_x_400mf_pretrained.onnx
  onnx_yaml_description: RegNetX-400MF (ImageNet) trained from torchvision and converted
    as ONNX
  onnx_yaml_name: regnet_x_400mf-imagenet-onnx
  production_ML_framework: PyTorch
  task_category: Classification
MC-93:
  card_name: RegNetY-1_6GF
  dataset: ImageNet-1K
  git_commit: bddbd7e6d65ecacc2e40cf6c9e2059669b8dbd44
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 224, 224]
  key_metric: Top1
  license: BSD-3-Clause
  model_repository: https://github.com/pytorch/vision
  model_subversion: v0.13.1
  native_ml_model_path: ax_models/model_cards/torchvision/classification/regnet_y_1_6gf-imagenet.yaml
  native_ml_model_weight: ''
  native_ml_yaml_description: RegNet_Y_1_6GF (ImageNet) - v1.5 from torchvision
  native_ml_yaml_name: regnet_y_1_6gf-imagenet
  num_classes: 1000
  onnx_model_path: ax_models/model_cards/torchvision/classification/regnet_y_1_6gf-imagenet-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/classification/regnet_y_1_6gf_pretrained.onnx
  onnx_yaml_description: RegNet_Y_1_6GF (ImageNet) trained from torchvision and converted
    as ONNX
  onnx_yaml_name: regnet_y_1_6gf-imagenet-onnx
  production_ML_framework: PyTorch
  task_category: Classification
MC-96:
  card_name: RegNetY-400MF
  dataset: ImageNet-1K
  git_commit: bddbd7e6d65ecacc2e40cf6c9e2059669b8dbd44
  input_color_format: RGB
  input_tensor_layout: NCHW
  input_tensor_shape: [1, 3, 224, 224]
  key_metric: Top1
  license: BSD-3-Clause
  model_repository: https://github.com/pytorch/vision
  model_subversion: v0.13.1
  native_ml_model_path: ax_models/model_cards/torchvision/classification/regnet_y_400mf-imagenet.yaml
  native_ml_model_weight: ''
  native_ml_yaml_description: RegNetY-400MF (ImageNet) - v1.5 from torchvision
  native_ml_yaml_name: regnet_y_400mf-imagenet
  num_classes: 1000
  onnx_model_path: ax_models/model_cards/torchvision/classification/regnet_y_400mf-imagenet-onnx.yaml
  onnx_model_weight: s3://axelera-model-card/weights/classification/regnet_y_400mf_pretrained.onnx
  onnx_yaml_description: RegNet_Y_400MF (ImageNet) trained from torchvision and converted
    as ONNX
  onnx_yaml_name: regnet_y_400mf-imagenet-onnx
  production_ML_framework: PyTorch
  task_category: Classification
