axelera-model-format: 1.0.0

name: mobilenetv2-imagenet

description: mobilenetv2 (ImageNet) from torchvision

pipeline:
  - mobilenetv2-imagenet:
      input:
        type: image
      preprocess:
        - resize:
            size: 256
        - centercrop:
            width: ${{input_width}}
            height: ${{input_height}}
        - torch-totensor:
        - normalize:
            mean: 0.485, 0.456, 0.406
            std: 0.229, 0.224, 0.225
      postprocess:
        - topk:
            k: 5

models:
  mobilenetv2-imagenet:
    class: AxTorchvisionMobileNetv2
    class_path: $AXELERA_FRAMEWORK/ax_models/torchvision/mobilenet.py
    task_category: Classification
    input_tensor_layout: NCHW
    input_tensor_shape: [1, 3, 224, 224]
    input_color_format: RGB # RGB, BGR, Gray
    dataset: ImageNet-1K
    num_classes: 1000
    extra_kwargs:
      torchvision_args:
        torchvision_weights_args:
          object: MobileNet_V2_Weights
          name: IMAGENET1K_V1

datasets:
  ImageNet-1K:
    class: TorchvisionDataAdapter
    class_path: $AXELERA_FRAMEWORK/ax_datasets/torchvision.py
    data_dir_name: ImageNet
    labels_path: $AXELERA_FRAMEWORK/ax_datasets/labels/imagenet1000_clsidx_to_labels.txt
    # Use COCO as representative images due to ImageNet's redistribution restrictions and large dataset size.
    # Suggest selecting 100-400 images from the ImageNet training dataset for representative images and
    # replacing the following representative_coco dataset with the selected images.
    repr_imgs_dir_path: $AXELERA_FRAMEWORK/data/coco2017_400_b680128
    repr_imgs_url: https://media.axelera.ai/artifacts/data/coco/coco2017_repr400.zip
    repr_imgs_md5: b680128512392586e3c86b670886d9fa
    # cal_data: /path/to/the/cal/dir
    # val_data: /path/to/the/val/dir
