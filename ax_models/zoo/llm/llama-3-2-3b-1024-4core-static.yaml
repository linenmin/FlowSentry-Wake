axelera-model-format: 1.0.0

name: llama-3-2-3b-1024-4core-static

description: HuggingFace Transformers Llama-3.2-3B-Instruct model, limiting the sequence length to 1024 tokens, compiled for 4 cores execution

models:
  llama-3-2-3b-1024-4core-static:
    precompiled_url: https://llm.axelera.ai/icdf/llama3b_1024_mc_model_v2.tar.gz
    precompiled_path: build/llama-3-2-3b-1024-4core-static/llama3b_1024_mc_model_v2.tar.gz
    precompiled_md5: fdb2ff6ff7c6f16c9cf5da5ef4a428a3
    task_category: LanguageModel
    extra_kwargs:
      llm:
        max_tokens: 1024
        embeddings_url: https://llm.axelera.ai/embeddings/llama_3_2_3b_embeddings.npz
        model_name: meta-llama/Llama-3.2-3B-Instruct
        tokenizer_url: https://llm.axelera.ai/embeddings/meta-llama_Llama-3.2-3B-Instruct_tokenizer.zip
