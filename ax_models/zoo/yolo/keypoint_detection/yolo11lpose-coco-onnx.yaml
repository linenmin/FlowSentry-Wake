axelera-model-format: 1.0.0

name: yolo11lpose-coco-onnx

description: (WIP) yolo11l pose estimation ultralytics v8.3.0, 640x640 (COCO)

pipeline:
  - keypoint_detections:
      model_name: yolo11lpose-coco-onnx
      input:
        type: image
      preprocess:
        - letterbox:
            height: ${{input_height}}
            scaleup: true
            width: ${{input_width}}
        - torch-totensor:
      inference:
        handle_all: false
      postprocess:
        - decodeyolopose:
            box_format: xywh
            conf_threshold: 0.25
            max_nms_boxes: 30000
            nms_iou_threshold: 0.45
            nms_top_k: 300
            normalized_coord: false
            eval:
              conf_threshold: 0.001
              nms_iou_threshold: 0.65

models:
  yolo11lpose-coco-onnx:
    class: AxONNXModel
    class_path: $AXELERA_FRAMEWORK/ax_models/base_onnx.py
    weight_path: weights/yolo11l-pose.onnx
    weight_url: https://media.axelera.ai/artifacts/model_cards/weights/yolo/keypoint_detection/yolo11l-pose.onnx
    weight_md5: a0c2124d8dfec01a427cc8b11bae0255
    task_category: KeypointDetection
    input_tensor_layout: NCHW
    input_tensor_shape: [1, 3, 640, 640]
    input_color_format: RGB
    num_classes: 1
    dataset: CocoDataset-keypoint-COCO2017
    extra_kwargs:
      compilation_config:
        quantization_scheme: per_tensor_min_max
        ignore_weight_buffers: false

datasets:
  CocoDataset-keypoint-COCO2017:
    class: KptDataAdapter
    class_path: $AXELERA_FRAMEWORK/ax_datasets/objdataadapter.py
    data_dir_name: coco
    label_type: COCO2017

operators:
  decodeyolopose:
    class: DecodeYoloPose
    class_path: $AXELERA_FRAMEWORK/ax_models/decoders/yolopose.py
