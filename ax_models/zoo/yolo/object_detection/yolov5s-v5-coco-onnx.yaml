axelera-model-format: 1.0.0

name: yolov5s-v5-coco-onnx

description: YOLOv5s-v5 ONNX with Focus layer, SiLU, S2D on the host, 640x640 (COCO)
# converted from https://github.com/ultralytics/yolov5/releases/download/v5.0/yolov5s.pt
# !python export.py --weights yolov5s.pt --include onnx --opset 11

pipeline:
  - detections:
      model_name: yolov5s-v5-coco-onnx
      input:
        type: image
      preprocess:
        - letterbox:
            width: ${{input_width}}
            height: ${{input_height}}
            scaleup: True
        - torch-totensor:
      postprocess:
        - decodeyolo:
            max_nms_boxes: 30000
            conf_threshold: 0.25
            nms_iou_threshold: 0.45
            nms_class_agnostic: False
            nms_top_k: 300
            box_format: xywh
            normalized_coord: False
            label_filter: ${{label_filter}}
            use_multi_label: False
            eval: # overrides for evaluating accuracy
              conf_threshold: 0.001
              nms_iou_threshold: 0.65
              use_multi_label: True
              nms_class_agnostic: False

models:
  yolov5s-v5-coco-onnx:
    class: AxONNXModel
    class_path: $AXELERA_FRAMEWORK/ax_models/base_onnx.py
    weight_path: weights/yolov5s-v5.onnx
    weight_url: https://media.axelera.ai/artifacts/model_cards/weights/yolo/object_detection/yolov5s-v5-op11.onnx
    weight_md5: d9d6d0c130fc0fe5c03cbcd8c727b6f7
    task_category: ObjectDetection
    input_tensor_layout: NCHW
    input_tensor_shape: [1, 3, 640, 640]
    input_color_format: RGB
    num_classes: 80
    dataset: CocoDataset-COCO2017
    extra_kwargs:
      YOLO:
        anchors_path: training_yamls/yolov5s.yaml # anchors are the same as yolov5s
        anchors_url: https://media.axelera.ai/artifacts/model_cards/artifacts/yolo/object_detection/cfgs/yolov5s.yaml
        anchors_md5: a41970402a188912070d5694bc62ed83
        #anchors: # or, specified explicitly
        #- [anchor, anchor, anchor]
        #- [anchor, anchor, anchor]
        #- [anchor, anchor, anchor]
        # strides: [8, 16, 32]  # specify if you are using a special version

datasets: # Python dataloader
  CocoDataset-COCO2017:
    class: ObjDataAdapter
    class_path: $AXELERA_FRAMEWORK/ax_datasets/objdataadapter.py
    data_dir_name: coco
    labels_path: $AXELERA_FRAMEWORK/ax_datasets/labels/coco.names
    # If using a custom dataset, comment out download year and add either
    # repr_imgs or cal_data for calibration and add val_data for validation.
    # You can use your existing training dataset as cal_data
    label_type: COCO2017
    repr_imgs_dir_path: $AXELERA_FRAMEWORK/data/coco2017_400_b680128
    repr_imgs_url: https://media.axelera.ai/artifacts/data/coco/coco2017_repr400.zip
    repr_imgs_md5: b680128512392586e3c86b670886d9fa
    # relative/path/to/your/cal_custom.json or dir with darknet label txt files
    # cal_data: train2017-400.txt
    # val_data: val2017.txt

operators:
  decodeyolo:
    class: DecodeYolo
    class_path: $AXELERA_FRAMEWORK/ax_models/decoders/yolo.py
