axelera-model-format: 1.0.0

name: fruit-demo

description: Cascade example - yolov8lpose cascaded with yolov8s (filtering for fruit) + yolov8sseg as parallel task

pipeline:
  - master_detections:
      model_name: yolov8lpose-coco-onnx
      input:
        type: image
      preprocess:
        - letterbox:
            width: 640
            height: 640
            scaleup: True
        - torch-totensor:
      inference:
        handle_all: False
      postprocess:
        - decodeyolopose:
            box_format: xywh # box format of the model output
            normalized_coord: False
            max_nms_boxes: 30000
            conf_threshold: 0.25
            nms_iou_threshold: 0.45
            nms_top_k: 300
  - segmentations:
      model_name: yolov8sseg-coco-onnx
      template_path: $AXELERA_FRAMEWORK/pipeline-template/yoloseg-letterbox.yaml
      input:
        type: image
        source: roi
        where: master_detections
        # Determine which identifier to use for the topk: biggest area, highest score, closest to the center.
        which: AREA # AREA, SCORE, CENTER
        # Play with this number to find your perfect number of cascaded detections. Higher topk means more RoIs into the segmentation.
        # At some point, the segmentations become the bottleneck of the system; num_frames_seg = num_input_frames * num_RoIs
        top_k: 5
      inference:
        handle_all: False
      postprocess:
        - decodeyoloseg:
            label_filter: banana, apple, orange
            max_nms_boxes: 30000
            conf_threshold: 0.25
            nms_iou_threshold: 0.45
            nms_top_k: 300
            unpad: True
  - object_detections:
      model_name: yolov8s-fruit
      input:
        type: image
#        source: roi
#        where: master_detections
#        which: AREA # AREA, SCORE, CENTER
#        top_k: 10
      preprocess:
        - letterbox:
            width: 640
            height: 640
            scaleup: True
        - torch-totensor:
      inference:
        handle_all: False
      postprocess:
        - decodeyolo:
            box_format: xywh # box format of the model output
            normalized_coord: False
            max_nms_boxes: 30000
            conf_threshold: 0.25
            nms_iou_threshold: 0.45
            nms_class_agnostic: True
            nms_top_k: 300
            use_multi_label: False
            label_filter: banana, apple, orange
            eval: # overrides for evaluating accuracy
              conf_threshold: 0.001
              nms_iou_threshold: 0.65
              use_multi_label: True
              nms_class_agnostic: False

operators:
  decodeyolopose:
    class: DecodeYoloPose
    class_path: $AXELERA_FRAMEWORK/ax_models/decoders/yolopose.py
  decodeyolo:
    class: DecodeYolo
    class_path: $AXELERA_FRAMEWORK/ax_models/decoders/yolo.py

models:
  yolov8lpose-coco-onnx:
    class: AxONNXModel
    class_path: $AXELERA_FRAMEWORK/ax_models/base_onnx.py
    weight_path: weights/yolov8l-pose-v8.1.onnx
    weight_url: https://media.axelera.ai/artifacts/model_cards/weights/yolo/keypoint_detection/yolov8l-pose-v8.1.onnx
    weight_md5: 60955674e106f59a14afcfec5d310f43
    task_category: KeypointDetection
    input_tensor_layout: NCHW
    input_tensor_shape: [1, 3, 640, 640]
    input_color_format: RGB
    num_classes: 1
    dataset: CocoDataset-COCO2017
    extra_kwargs:
      aipu_cores: 1
  yolov8s-fruit:
    class: AxONNXModel
    class_path: $AXELERA_FRAMEWORK/ax_models/base_onnx.py
    weight_path: weights/yolov8s_ultralytics_v8.1.0.onnx
    weight_url: https://media.axelera.ai/artifacts/model_cards/weights/yolo/object_detection/yolov8s_ultralytics_v8.1.0.onnx
    weight_md5: b16cc786a276cdc58928416c19d8aa56
    task_category: ObjectDetection
    input_tensor_layout: NCHW
    input_tensor_shape: [1, 3, 640, 640]
    input_color_format: RGB
    num_classes: 80
    dataset: CocoDataset-COCO2017
    extra_kwargs:
      aipu_cores: 1
  yolov8sseg-coco-onnx:
    class: AxONNXModel
    class_path: $AXELERA_FRAMEWORK/ax_models/base_onnx.py
    weight_path: weights/yolov8s-seg-v8.2.onnx
    weight_url: https://media.axelera.ai/artifacts/model_cards/weights/yolo/instance_segmentation/yolov8s-seg-v8.2.onnx
    weight_md5: f773576dba47b14b9ed2b86ea3c3a00f
    task_category: InstanceSegmentation
    input_tensor_layout: NCHW
    input_tensor_shape: [1, 3, 640, 640]
    input_color_format: RGB
    num_classes: 80
    dataset: CocoDataset-COCO2017
    extra_kwargs:
      aipu_cores: 2 # Use 2 cores for segmentation to speed up inference, as each RoI duplicates the number of incoming images

datasets:
  CocoDataset-COCO2017:
    class: ObjDataAdapter
    class_path: $AXELERA_FRAMEWORK/ax_datasets/objdataadapter.py
    data_dir_name: coco
    labels_path: $AXELERA_FRAMEWORK/ax_datasets/labels/coco.names
    label_type: COCO2017
